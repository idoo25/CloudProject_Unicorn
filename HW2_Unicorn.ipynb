{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YairZen/CloudProject_Unicorn/blob/lior/HW2_UNICORN_DEV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ PIP INSTALL (GLOBAL)"
      ],
      "metadata": {
        "id": "uxU3y_ahSBCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade gradio pandas matplotlib python-docx\n",
        "!pip install -q --upgrade firebase-admin plotly gdown"
      ],
      "metadata": {
        "id": "QD6QB2FYWlkD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ IMPORTS (GLOBAL)"
      ],
      "metadata": {
        "id": "dXiHxUFpa556"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "import requests\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#######\n",
        "# Report Generator with DOCX Export\n",
        "from docx import Document\n",
        "import tempfile\n",
        "import os\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
        "\n",
        "# Firebase imports\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, db\n",
        "\n",
        "# Additional imports for IoT Dashboard\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "from datetime import timedelta\n",
        "import gdown\n",
        "import json\n",
        "\n",
        "# Plotly imports\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import numpy as np\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#--------RAG & Index-------------#\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from urllib.parse import quote\n",
        "\n",
        "# --- Web fetch + HTML parsing ---\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# --- NLP (stemming / stopwords) ---\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n"
      ],
      "metadata": {
        "id": "PkZpGdnxM6az",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aecc7967-8ece-414c-a258-310355875cea"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firebase Configuration"
      ],
      "metadata": {
        "id": "ZSPgJzDMOn_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Firebase credentials\n",
        "FIREBASE_KEY_ID = '1ESnh8BIbGKrVEijA9nKNgNJNdD5kAaYC'\n",
        "firebase_key_file = 'firebase_key.json'\n",
        "#add for the RAG & INDEX CODE#\n",
        "FIREBASE_URL = \"https://cloud-81451-default-rtdb.europe-west1.firebasedatabase.app/\"\n",
        "#-----#\n",
        "if os.path.exists(firebase_key_file):\n",
        "    os.remove(firebase_key_file)\n",
        "\n",
        "print(' Downloading Firebase credentials...')\n",
        "try:\n",
        "    url = f'https://drive.google.com/uc?id={FIREBASE_KEY_ID}'\n",
        "    gdown.download(url, firebase_key_file, quiet=False, fuzzy=True)\n",
        "    with open(firebase_key_file, 'r') as f:\n",
        "        creds = json.load(f)\n",
        "    print(f'‚úì Project: {creds.get(\"project_id\")}')\n",
        "except Exception as e:\n",
        "    print(f'‚ö†Ô∏è Error: {e}')\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        os.rename(list(uploaded.keys())[0], firebase_key_file)\n",
        "\n",
        "# Initialize Firebase\n",
        "if not firebase_admin._apps:\n",
        "    firebase_admin.initialize_app(\n",
        "        credentials.Certificate(firebase_key_file),\n",
        "        {'databaseURL': 'https://cloud-81451-default-rtdb.europe-west1.firebasedatabase.app/'}\n",
        "    )\n",
        "    print(' Firebase initialized')\n",
        "\n",
        "# Server Configuration (already exists in Cell 6, but adding here for completeness)\n",
        "BATCH_LIMIT = 200\n",
        "\n",
        "print(' Firebase configured')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGLzSlUNOmJ0",
        "outputId": "382739b9-58eb-4e7d-d17b-0b150e7a943a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Downloading Firebase credentials...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ESnh8BIbGKrVEijA9nKNgNJNdD5kAaYC\n",
            "To: /content/firebase_key.json\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.37k/2.37k [00:00<00:00, 4.24MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Project: cloud-81451\n",
            " Firebase configured\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Downloading Firebase credentials...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ESnh8BIbGKrVEijA9nKNgNJNdD5kAaYC\n",
            "To: /content/firebase_key.json\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.37k/2.37k [00:00<00:00, 1.70MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Project: cloud-81451\n",
            " Firebase configured\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîÑ Firebase Sync Functions"
      ],
      "metadata": {
        "id": "j3VvQJgmOu6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sync Functions\n",
        "\n",
        "def get_latest_timestamp_from_firebase():\n",
        "    try:\n",
        "        latest = db.reference('/sensor_data').order_by_child('created_at').limit_to_last(1).get()\n",
        "        return list(latest.values())[0]['created_at'] if latest else None\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def fetch_batch_from_server(before_timestamp=None):\n",
        "    params = {\"feed\": FEED, \"limit\": BATCH_LIMIT}\n",
        "    if before_timestamp:\n",
        "        params[\"before_created_at\"] = before_timestamp\n",
        "    try:\n",
        "        return requests.get(f\"{BASE_URL}/history\", params=params, timeout=180).json()\n",
        "    except:\n",
        "        return {}\n",
        "\n",
        "def save_sensor_data_to_firebase(data_list):\n",
        "    if not data_list:\n",
        "        return 0\n",
        "\n",
        "    ref = db.reference('/sensor_data')\n",
        "    saved = 0\n",
        "\n",
        "    for sample in data_list:\n",
        "        try:\n",
        "            vals = json.loads(sample['value'])\n",
        "            temperature = max(-50, min(100, float(vals['temperature'])))\n",
        "            humidity = max(0, min(100, float(vals['humidity'])))\n",
        "            soil = max(0, min(100, float(vals['soil'])))\n",
        "            timestamp_key = sample['created_at'].replace(':', '-').replace('.', '-')\n",
        "\n",
        "            ref.child(timestamp_key).set({\n",
        "                'created_at': sample['created_at'],\n",
        "                'temperature': temperature,\n",
        "                'humidity': humidity,\n",
        "                'soil': soil\n",
        "            })\n",
        "\n",
        "            saved += 1\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    return saved\n",
        "\n",
        "def sync_new_data_from_server():\n",
        "    msgs = [\"Starting sync...\"]\n",
        "    latest = get_latest_timestamp_from_firebase()\n",
        "    msgs.append(f\"Latest: {latest}\" if latest else \"No existing data\")\n",
        "    resp = fetch_batch_from_server()\n",
        "\n",
        "    if \"data\" not in resp:\n",
        "        return \"\\n\".join(msgs + [\"Error fetching data\"]), 0\n",
        "\n",
        "    new = [s for s in resp[\"data\"] if not latest or s[\"created_at\"] > latest]\n",
        "\n",
        "    if new:\n",
        "        saved = save_sensor_data_to_firebase(new)\n",
        "        return \"\\n\".join(msgs + [f\"Found {len(new)} new\", f\"Saved {saved}!\"]), saved\n",
        "\n",
        "    return \"\\n\".join(msgs + [\"No new data\"]), 0\n",
        "\n",
        "print('Sync functions loaded')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXeOpqeCOwvs",
        "outputId": "fabccf94-6dbf-4a92-f207-8324d728ba84"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sync functions loaded\n",
            "Sync functions loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Data Loading"
      ],
      "metadata": {
        "id": "i_Vu19SqO2Ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Data Loading (YOUR ORIGINAL CODE)\n",
        "\n",
        "def load_data_from_firebase():\n",
        "    data = db.reference('/sensor_data').get()\n",
        "    if not data:\n",
        "        return pd.DataFrame()\n",
        "    df = pd.DataFrame([{\n",
        "        'timestamp': pd.to_datetime(v['created_at']),\n",
        "        'temperature': float(v['temperature']),\n",
        "        'humidity': float(v['humidity']),\n",
        "        'soil': float(v['soil'])\n",
        "    } for v in data.values()])\n",
        "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "    df['humidity'] = df['humidity'].clip(0, 100)\n",
        "    df['soil'] = df['soil'].clip(0, 100)\n",
        "    df['temperature'] = df['temperature'].clip(-50, 100)\n",
        "    return df\n",
        "\n",
        "print('‚úÖ Data loading ready')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdmkuJAZO3iv",
        "outputId": "06ed2e3a-0451-4fbb-ed66-2920f7dc5c17"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data loading ready\n",
            "‚úÖ Data loading ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ GLOBAL CONFIG / THEME / CSS (OPTIONAL)"
      ],
      "metadata": {
        "id": "lJqc9RlyNbcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Configuration\n",
        "\n",
        "# ============================================================================\n",
        "# SERVER & FEED CONFIGURATION (YOUR ORIGINAL SETTINGS)\n",
        "# ============================================================================\n",
        "FEED = \"json\"  # Your feed name - CHANGE THIS if different\n",
        "BASE_URL = \"https://server-cloud-v645.onrender.com/\"\n",
        "BATCH_LIMIT = 200\n",
        "\n",
        "# ============================================================================\n",
        "# APP CONFIGURATION\n",
        "# ============================================================================\n",
        "APP_TITLE = \"üå± CloudGarden\"\n",
        "APP_SUBTITLE = \"Smart Plant Disease Detection System\"\n",
        "\n",
        "# --- Colors for Friend's Realtime Dashboard ---\n",
        "COLOR_TEMP = \"#1f77b4\"   # blue\n",
        "COLOR_HUM  = \"#ff7f0e\"   # orange\n",
        "COLOR_SOIL = \"#2ca02c\"   # green\n",
        "\n",
        "STATUS_OK_COLOR = \"#2ca02c\"      # green\n",
        "STATUS_WARN_COLOR = \"#ffbf00\"    # yellow\n",
        "STATUS_BAD_COLOR = \"#d62728\"     # red\n",
        "\n",
        "# --- ML Model Configuration ---\n",
        "MODEL_NAME = \"linkanjarad/mobilenet_v2_1.0_224-plant-disease-identification\"\n",
        "clf = pipeline(\"image-classification\", model=MODEL_NAME)\n",
        "\n",
        "# ============================================================================\n",
        "# CSS STYLING FOR IOT DASHBOARD\n",
        "# ============================================================================\n",
        "\n",
        "COLORS = {\n",
        "    'temperature': {'color': '#ef4444'},\n",
        "    'humidity': {'color': '#3b82f6'},\n",
        "    'soil': {'color': '#8b5cf6'}\n",
        "}\n",
        "\n",
        "CUSTOM_CSS = \"\"\"\n",
        "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');\n",
        "* { font-family: 'Inter', sans-serif; }\n",
        "\n",
        ".kpi-card {\n",
        "    background: white;\n",
        "    padding: 24px;\n",
        "    border-radius: 12px;\n",
        "    box-shadow: 0 1px 3px rgba(0,0,0,0.12);\n",
        "    text-align: center;\n",
        "    border-left: 4px solid;\n",
        "}\n",
        ".kpi-label { color: #6b7280; font-size: 14px; font-weight: 600; }\n",
        ".kpi-value { font-size: 48px; font-weight: 700; color: #1f2937; }\n",
        ".trend-up { color: #10b981; }\n",
        ".trend-down { color: #ef4444; }\n",
        "\n",
        "/* Tooltip styles */\n",
        ".info-icon {\n",
        "    position: relative;\n",
        "    display: inline-flex;\n",
        "    cursor: help;\n",
        "}\n",
        "\n",
        ".info-icon .tooltip-text {\n",
        "    visibility: hidden;\n",
        "    width: 200px;\n",
        "    background-color: #1f2937;\n",
        "    color: white;\n",
        "    text-align: center;\n",
        "    border-radius: 6px;\n",
        "    padding: 8px;\n",
        "    position: absolute;\n",
        "    z-index: 1000;\n",
        "    bottom: 125%;\n",
        "    left: 50%;\n",
        "    margin-left: -100px;\n",
        "    opacity: 0;\n",
        "    transition: opacity 0.3s;\n",
        "    font-size: 11px;\n",
        "    line-height: 1.4;\n",
        "    box-shadow: 0 2px 8px rgba(0,0,0,0.2);\n",
        "}\n",
        "\n",
        ".info-icon .tooltip-text::after {\n",
        "    content: \"\";\n",
        "    position: absolute;\n",
        "    top: 100%;\n",
        "    left: 50%;\n",
        "    margin-left: -5px;\n",
        "    border-width: 5px;\n",
        "    border-style: solid;\n",
        "    border-color: #1f2937 transparent transparent transparent;\n",
        "}\n",
        "\n",
        ".info-icon:hover .tooltip-text {\n",
        "    visibility: visible;\n",
        "    opacity: 1;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "print('‚úÖ Configuration loaded')\n",
        "print(f'üì° Server: {BASE_URL}')\n",
        "print(f'üìª Feed: {FEED}')\n",
        "print(f'üì¶ Batch limit: {BATCH_LIMIT}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz7Tm5DJM7hn",
        "outputId": "6791fb4b-3647-4f93-a973-458ee8f369c1"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Configuration loaded\n",
            "üì° Server: https://server-cloud-v645.onrender.com/\n",
            "üìª Feed: json\n",
            "üì¶ Batch limit: 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Configuration loaded\n",
            "üì° Server: https://server-cloud-v645.onrender.com/\n",
            "üìª Feed: json\n",
            "üì¶ Batch limit: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ TAB REGISTRY (MODULAR)\n",
        "\n",
        " ◊û◊ï◊°◊ô◊§◊ô◊ù ◊ó◊ú◊ï◊†◊ô◊™ ◊ó◊ì◊©◊î ◊®◊ß ◊¢\"◊ô:\n",
        " 1) ◊î◊ï◊°◊§◊™ TAB1 Logic - ◊õ◊ú ◊î◊§◊ï◊†◊ß◊¶◊ô◊ï◊™ ◊¢◊ñ◊® ◊ú◊û◊ô◊†◊î◊ù.\n",
        " 2) ◊î◊ï◊°◊§◊™ Tab1 GUI - ◊õ◊ú GRADIO\n",
        " * ◊ô◊© ◊ú◊î◊ï◊®◊ô◊ì ◊ê◊™ \"with gr.Blocks() as demo:\" ◊ï \"demo.launch()\"\n",
        "\n",
        " 3) ◊ú◊î◊ï◊°◊ô◊£ ◊ê◊™ ◊©◊ù ◊î◊§◊ï◊†◊ß◊¶◊ô◊ô◊™ GUI ◊ú◊®◊©◊ô◊û◊™ ◊îTAB ◊ú◊û◊ò◊î."
      ],
      "metadata": {
        "id": "ISU3vcbDNf1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ TAB 1 Logic -  üå± Realtime Dashboard\n"
      ],
      "metadata": {
        "id": "zNQNqiEsWqfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------- Core Data Fetch ----------\n",
        "def load_iot_data(feed: str, limit: int) -> pd.DataFrame | None:\n",
        "    resp = requests.get(\n",
        "        f\"{BASE_URL}/history\",\n",
        "        params={\"feed\": feed, \"limit\": limit},\n",
        "        timeout=30\n",
        "    )\n",
        "    data = resp.json()\n",
        "    if \"data\" not in data or not data[\"data\"]:\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame(data[\"data\"])\n",
        "    if \"created_at\" not in df.columns or \"value\" not in df.columns:\n",
        "        return None\n",
        "\n",
        "    df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], errors=\"coerce\", utc=True)\n",
        "    df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"created_at\", \"value\"]).sort_values(\"created_at\")\n",
        "\n",
        "    return None if df.empty else df\n",
        "\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def normalize(series: pd.Series) -> pd.Series:\n",
        "    mn, mx = float(series.min()), float(series.max())\n",
        "    if mx - mn == 0:\n",
        "        return series * 0.0\n",
        "    return (series - mn) / (mx - mn)\n",
        "\n",
        "\n",
        "# ---------- Plant Status + Plots ----------\n",
        "def plant_dashboard(limit: int):\n",
        "    try:\n",
        "        dfs = {\n",
        "            \"temperature\": load_iot_data(\"temperature\", limit),\n",
        "            \"humidity\": load_iot_data(\"humidity\", limit),\n",
        "            \"soil\": load_iot_data(\"soil\", limit),\n",
        "        }\n",
        "\n",
        "        missing = [k for k, v in dfs.items() if v is None]\n",
        "        if missing:\n",
        "            return \"‚ö†Ô∏è Partial Data\", f\"Missing sensors or empty history: {', '.join(missing)}\", None, None, None, None\n",
        "\n",
        "        temp = float(dfs[\"temperature\"][\"value\"].iloc[-1])\n",
        "        hum = float(dfs[\"humidity\"][\"value\"].iloc[-1])\n",
        "        soil = float(dfs[\"soil\"][\"value\"].iloc[-1])\n",
        "\n",
        "        issues, warnings = [], []\n",
        "\n",
        "        checks = [\n",
        "            (\"Temperature\", temp, 18, 32, 1),\n",
        "            (\"Air humidity\", hum, 35, 75, 3),\n",
        "            (\"Soil moisture\", soil, 20, 60, 3),\n",
        "        ]\n",
        "\n",
        "        for name, value, low, high, margin in checks:\n",
        "            if not (low <= value <= high):\n",
        "                issues.append(f\"{name} out of range ({value:.1f})\")\n",
        "            elif value <= low + margin or value >= high - margin:\n",
        "                warnings.append(f\"{name} near limit ({value:.1f})\")\n",
        "\n",
        "        if issues:\n",
        "            status = \"üî¥ Plant Status: Not OK\"\n",
        "            details_main = \" ; \".join(issues)\n",
        "\n",
        "        elif warnings:\n",
        "            status = \"üü° Plant Status: Warning\"\n",
        "            details_main = \" ; \".join(warnings)\n",
        "\n",
        "        else:\n",
        "            status = \"üü¢ Plant Status: OK\"\n",
        "            details_main = \"All sensors are within valid ranges\"\n",
        "\n",
        "        details = (\n",
        "    f\"{details_main}\\n\"\n",
        "    f\"Latest values:\\n\"\n",
        "    f\"temp={temp:.1f}\\n\"\n",
        "    f\"humidity={hum:.1f}\\n\"\n",
        "    f\"soil={soil:.1f}\"\n",
        "\n",
        "        )\n",
        "\n",
        "        df_t, df_h, df_s = dfs[\"temperature\"], dfs[\"humidity\"], dfs[\"soil\"]\n",
        "\n",
        "        fig_t = plt.figure(figsize=(7, 3.2))\n",
        "        plt.plot(df_t[\"created_at\"], df_t[\"value\"], marker=\"o\", color=COLOR_TEMP)\n",
        "        plt.title(\"Temperature History\")\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"¬∞C\")\n",
        "        plt.grid(True)\n",
        "\n",
        "        fig_h = plt.figure(figsize=(7, 3.2))\n",
        "        plt.plot(df_h[\"created_at\"], df_h[\"value\"], marker=\"o\", color=COLOR_HUM)\n",
        "        plt.title(\"Air Humidity History\")\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"%\")\n",
        "        plt.grid(True)\n",
        "\n",
        "        fig_s = plt.figure(figsize=(7, 3.2))\n",
        "        plt.plot(df_s[\"created_at\"], df_s[\"value\"], marker=\"o\", color=COLOR_SOIL)\n",
        "        plt.title(\"Soil Moisture History\")\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"%\")\n",
        "        plt.grid(True)\n",
        "\n",
        "        fig_c = plt.figure(figsize=(10, 3.4))\n",
        "        plt.plot(df_t[\"created_at\"], normalize(df_t[\"value\"]), marker=\"o\", label=\"Temperature (norm)\", color=COLOR_TEMP)\n",
        "        plt.plot(df_h[\"created_at\"], normalize(df_h[\"value\"]), marker=\"o\", label=\"Humidity (norm)\", color=COLOR_HUM)\n",
        "        plt.plot(df_s[\"created_at\"], normalize(df_s[\"value\"]), marker=\"o\", label=\"Soil (norm)\", color=COLOR_SOIL)\n",
        "        plt.title(\"Combined Trend (Normalized)\")\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"Normalized Value (0‚Äì1)\")\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "\n",
        "        return status, details, fig_t, fig_h, fig_s, fig_c\n",
        "\n",
        "    except Exception:\n",
        "        return \"‚ùå Error\", \"Failed to fetch data from server. Please try again.\", None, None, None, None\n"
      ],
      "metadata": {
        "id": "UNh-iF2WWqLB"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Tab 1 GUI - - üå± Realtime Dashboard\n"
      ],
      "metadata": {
        "id": "xbBhAJeHXGSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_realtime_dashboard_tab():\n",
        "    gr.Markdown(\n",
        "    \"<h3 style='margin:0; font-size:22px;'>üåø Overall Plant Status (Real-Time)</h3>\"\n",
        ")\n",
        "\n",
        "\n",
        "    samples = gr.Slider(1, 200, value=20, step=1, label=\"Number of Samples (used for all graphs)\")\n",
        "    overall_btn = gr.Button(\"Update Plant Dashboard\", variant=\"primary\")\n",
        "\n",
        "\n",
        "\n",
        "    overall_status = gr.Textbox(\n",
        "        label=\"Overall Status\",\n",
        "        lines=1,\n",
        "        placeholder=\"Click 'Update Plant Dashboard' to evaluate plant status\"\n",
        "    )\n",
        "    overall_info = gr.Textbox(\n",
        "        label=\"Status Details\",\n",
        "        lines=4,\n",
        "        placeholder=\"Detailed plant analysis will appear here\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        gr.Markdown(f\"\"\"\n",
        "<div class=\"legend-card\" style=\"margin-top:14px;padding:14px;border:1px solid var(--border-color-primary)\n",
        ";border-radius:10px;\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  <h4 style=\"margin-bottom:10px; font-size:20px; font-weight:600;\">\n",
        "üåø Plant Status\n",
        "</h4>\n",
        "\n",
        "\n",
        "  <span style=\"color:{STATUS_OK_COLOR};font-size:26px;\">‚óè</span>\n",
        "  <b>Healthy</b> ‚Äì All sensor values within normal ranges<br>\n",
        "\n",
        "  <span style=\"color:{STATUS_WARN_COLOR};font-size:26px;\">‚óè</span>\n",
        "  <b>Warning</b> ‚Äì At least one value near threshold<br>\n",
        "\n",
        "  <span style=\"color:{STATUS_BAD_COLOR};font-size:26px;\">‚óè</span>\n",
        "  <b>Not OK</b> ‚Äì One or more values out of range<br><br>\n",
        "\n",
        "  <span>Status is calculated automatically from sensor data</span>\n",
        "</div>\n",
        "        \"\"\")\n",
        "\n",
        "        gr.Markdown(f\"\"\"\n",
        "<div class=\"legend-card\" style=\"margin-top:14px;padding:14px;border:1px solid var(--border-color-primary)\n",
        ";border-radius:10px;\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  <h4 style=\"margin-bottom:10px; font-size:20px; font-weight:600;\">\n",
        "‚ÑπÔ∏è Valid Value Ranges\n",
        "</h4>\n",
        "\n",
        "\n",
        "  <span style=\"color:{COLOR_TEMP};font-size:26px;\">‚óè</span>\n",
        "  üå°Ô∏è <b>Temperature</b>: 18‚Äì32¬∞C<br>\n",
        "\n",
        "  <span style=\"color:{COLOR_HUM};font-size:26px;\">‚óè</span>\n",
        "  üíß <b>Air Humidity</b>: 35‚Äì75%<br>\n",
        "\n",
        "  <span style=\"color:{COLOR_SOIL};font-size:26px;\">‚óè</span>\n",
        "  üå± <b>Soil Moisture</b>: 20‚Äì60%<br><br>\n",
        "\n",
        "  <span>‚ö†Ô∏è Values outside these ranges are considered abnormal</span>\n",
        "</div>\n",
        "        \"\"\")\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "<h2 style=\"text-align:center; margin-top:22px; font-size:26px; font-weight:600;\">\n",
        "üìà Plant Sensor Graphs\n",
        "</h2>\n",
        "\"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        plot_temp = gr.Plot(label=\"Temperature\")\n",
        "        plot_hum = gr.Plot(label=\"Air Humidity\")\n",
        "\n",
        "    with gr.Row():\n",
        "        plot_soil = gr.Plot(label=\"Soil Moisture\")\n",
        "        plot_combined = gr.Plot(label=\"Combined (Normalized)\")\n",
        "\n",
        "    overall_btn.click(\n",
        "        fn=plant_dashboard,\n",
        "        inputs=[samples],\n",
        "        outputs=[overall_status, overall_info, plot_temp, plot_hum, plot_soil, plot_combined]\n",
        "    )"
      ],
      "metadata": {
        "id": "Mw1loVKKYxN0"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ TAB 3 LOGIC - üìÑ Generate Report"
      ],
      "metadata": {
        "id": "diLmmpb6NPNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- TAB: Generate Report (LOGIC) ----------\n",
        "\n",
        "def unify_sensor_dfs(dfs: dict) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Robustly convert unicorn dfs into a single dataframe:\n",
        "    supports timestamp as column OR as index.\n",
        "    Output columns:\n",
        "    timestamp | temperature | humidity | soil\n",
        "    \"\"\"\n",
        "    def prep(df, col):\n",
        "        if df is None or df.empty:\n",
        "            return pd.DataFrame(columns=[\"timestamp\", col])\n",
        "\n",
        "        out = df.copy()\n",
        "\n",
        "        # Case 1: timestamp is an index\n",
        "        if \"timestamp\" not in out.columns:\n",
        "            if out.index.name is not None:\n",
        "                out = out.reset_index()\n",
        "            else:\n",
        "                # unnamed index ‚Üí assume it's timestamp\n",
        "                out = out.reset_index().rename(columns={\"index\": \"timestamp\"})\n",
        "\n",
        "        # Now timestamp should exist\n",
        "        if \"timestamp\" not in out.columns or \"value\" not in out.columns:\n",
        "            return pd.DataFrame(columns=[\"timestamp\", col])\n",
        "\n",
        "        out = out[[\"timestamp\", \"value\"]]\n",
        "        out[\"timestamp\"] = pd.to_datetime(out[\"timestamp\"], errors=\"coerce\")\n",
        "        out = out.dropna(subset=[\"timestamp\"])\n",
        "        out = out.rename(columns={\"value\": col})\n",
        "        return out\n",
        "\n",
        "    t = prep(dfs.get(\"temperature\"), \"temperature\")\n",
        "    h = prep(dfs.get(\"humidity\"), \"humidity\")\n",
        "    s = prep(dfs.get(\"soil\"), \"soil\")\n",
        "\n",
        "    df = t.merge(h, on=\"timestamp\", how=\"outer\").merge(s, on=\"timestamp\", how=\"outer\")\n",
        "    df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "def create_docx_report(dfs: dict, limit: int) -> str:\n",
        "    \"\"\"\n",
        "    Creates a DOCX report in a combined-like style (English), without AI:\n",
        "    - Executive Summary (rules-based)\n",
        "    - Environmental Conditions table (Current / Average / Range)\n",
        "    - Statistical Summary\n",
        "    \"\"\"\n",
        "    df = unify_sensor_dfs(dfs)\n",
        "\n",
        "    if df is None or df.empty:\n",
        "        raise ValueError(\"No data available for report\")\n",
        "\n",
        "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"timestamp\"])\n",
        "\n",
        "    # choose \"daily\" as last 100 rows (like combined did)\n",
        "    daily = df.tail(100)\n",
        "\n",
        "    # helper stats safely\n",
        "    def col_stats(col):\n",
        "        if col not in daily.columns:\n",
        "            return None\n",
        "        series = daily[col].dropna()\n",
        "        if series.empty:\n",
        "            return None\n",
        "        return {\n",
        "            \"current\": float(series.iloc[-1]),\n",
        "            \"avg\": float(series.mean()),\n",
        "            \"min\": float(series.min()),\n",
        "            \"max\": float(series.max()),\n",
        "        }\n",
        "\n",
        "    stats_temp = col_stats(\"temperature\")\n",
        "    stats_hum = col_stats(\"humidity\")\n",
        "    stats_soil = col_stats(\"soil\")\n",
        "\n",
        "    # -------- Rules-based Executive Summary (English) --------\n",
        "    def build_summary():\n",
        "        parts = []\n",
        "        parts.append(f\"Daily plant health report generated from the latest sensor readings (up to {limit} samples per sensor).\")\n",
        "\n",
        "        issues = []\n",
        "        # simple thresholds (adjust if you want)\n",
        "        if stats_soil and stats_soil[\"avg\"] < 30:\n",
        "            issues.append(\"Soil moisture is low on average, which may cause water stress.\")\n",
        "        if stats_hum and stats_hum[\"avg\"] < 40:\n",
        "            issues.append(\"Humidity is low, which can increase dryness and stress for some plants.\")\n",
        "        if stats_hum and stats_hum[\"avg\"] > 70:\n",
        "            issues.append(\"Humidity is high, which may increase fungal risk without proper ventilation.\")\n",
        "        if stats_temp and stats_temp[\"avg\"] > 30:\n",
        "            issues.append(\"Temperature is relatively high on average; heat stress is possible.\")\n",
        "        if stats_temp and stats_temp[\"avg\"] < 15:\n",
        "            issues.append(\"Temperature is relatively low on average; cold stress is possible.\")\n",
        "\n",
        "        if not issues:\n",
        "            parts.append(\"Overall environmental conditions look stable and within common recommended ranges.\")\n",
        "        else:\n",
        "            parts.append(\"Potential risks identified based on averages:\")\n",
        "            parts.extend([f\"- {x}\" for x in issues])\n",
        "\n",
        "        recs = []\n",
        "        if stats_soil and stats_soil[\"avg\"] < 30:\n",
        "            recs.append(\"Increase watering and verify soil drainage.\")\n",
        "        if stats_hum and stats_hum[\"avg\"] < 40:\n",
        "            recs.append(\"Increase humidity (misting/humidifier) and avoid dry airflow.\")\n",
        "        if stats_hum and stats_hum[\"avg\"] > 70:\n",
        "            recs.append(\"Improve ventilation to reduce fungal risk.\")\n",
        "        if stats_temp and stats_temp[\"avg\"] > 30:\n",
        "            recs.append(\"Move the plant to a cooler/shaded area and monitor watering.\")\n",
        "        if stats_temp and stats_temp[\"avg\"] < 15:\n",
        "            recs.append(\"Move the plant to a warmer spot and avoid cold drafts.\")\n",
        "\n",
        "        # keep it short like combined (3-4 paragraphs)\n",
        "        if not recs:\n",
        "            parts.append(\"Recommendations: keep monitoring trends and maintain the current care routine.\")\n",
        "        else:\n",
        "            parts.append(\"Recommendations:\")\n",
        "            parts.extend([f\"- {r}\" for r in recs[:3]])\n",
        "\n",
        "        return \"\\n\".join(parts)\n",
        "\n",
        "    summary_text = build_summary()\n",
        "\n",
        "    # -------- Build DOCX --------\n",
        "    doc = Document()\n",
        "\n",
        "    title = doc.add_heading(\"üå± Daily Plant Health Report\", 0)\n",
        "    title.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "\n",
        "    date_para = doc.add_paragraph()\n",
        "    date_run = date_para.add_run(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\")\n",
        "    date_run.bold = True\n",
        "    date_para.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "\n",
        "    # Executive Summary\n",
        "    doc.add_heading(\"Executive Summary\", 1)\n",
        "    doc.add_paragraph(summary_text)\n",
        "\n",
        "    # Environmental Conditions Table\n",
        "    doc.add_heading(\"Environmental Conditions\", 1)\n",
        "\n",
        "    table = doc.add_table(rows=4, cols=4)\n",
        "    table.style = \"Light Grid Accent 1\"\n",
        "\n",
        "    headers = table.rows[0].cells\n",
        "    headers[0].text = \"Parameter\"\n",
        "    headers[1].text = \"Current\"\n",
        "    headers[2].text = \"Average\"\n",
        "    headers[3].text = \"Range\"\n",
        "\n",
        "    # Temperature row\n",
        "    row1 = table.rows[1].cells\n",
        "    row1[0].text = \"üå°Ô∏è Temperature\"\n",
        "    if stats_temp:\n",
        "        row1[1].text = f\"{stats_temp['current']:.1f}¬∞C\"\n",
        "        row1[2].text = f\"{stats_temp['avg']:.1f}¬∞C\"\n",
        "        row1[3].text = f\"{stats_temp['min']:.1f}-{stats_temp['max']:.1f}¬∞C\"\n",
        "    else:\n",
        "        row1[1].text = row1[2].text = row1[3].text = \"‚Äî\"\n",
        "\n",
        "    # Humidity row\n",
        "    row2 = table.rows[2].cells\n",
        "    row2[0].text = \"üíß Humidity\"\n",
        "    if stats_hum:\n",
        "        row2[1].text = f\"{stats_hum['current']:.1f}%\"\n",
        "        row2[2].text = f\"{stats_hum['avg']:.1f}%\"\n",
        "        row2[3].text = f\"{stats_hum['min']:.1f}-{stats_hum['max']:.1f}%\"\n",
        "    else:\n",
        "        row2[1].text = row2[2].text = row2[3].text = \"‚Äî\"\n",
        "\n",
        "    # Soil row\n",
        "    row3 = table.rows[3].cells\n",
        "    row3[0].text = \"üå± Soil Moisture\"\n",
        "    if stats_soil:\n",
        "        row3[1].text = f\"{stats_soil['current']:.1f}%\"\n",
        "        row3[2].text = f\"{stats_soil['avg']:.1f}%\"\n",
        "        row3[3].text = f\"{stats_soil['min']:.1f}-{stats_soil['max']:.1f}%\"\n",
        "    else:\n",
        "        row3[1].text = row3[2].text = row3[3].text = \"‚Äî\"\n",
        "\n",
        "    # Statistical Summary\n",
        "    doc.add_heading(\"Statistical Summary\", 1)\n",
        "\n",
        "    start = df[\"timestamp\"].min()\n",
        "    end = df[\"timestamp\"].max()\n",
        "\n",
        "    stats_text = (\n",
        "        f\"Total Readings: {len(df)}\\n\"\n",
        "        f\"Time Period: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\\n\"\n",
        "        \"Data Points: Temperature, Humidity, Soil Moisture\\n\"\n",
        "        \"Quality: Based on available API readings\"\n",
        "    )\n",
        "    doc.add_paragraph(stats_text)\n",
        "\n",
        "    fd, path = tempfile.mkstemp(suffix=\".docx\", prefix=\"daily_report_\")\n",
        "    os.close(fd)\n",
        "    doc.save(path)\n",
        "    return path\n",
        "\n",
        "\n",
        "\n",
        "def generate_report_screen(limit: int):\n",
        "    \"\"\"\n",
        "    Button handler for the Generate Report tab.\n",
        "    Returns: (status_text, file_path_or_None)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        dfs = {\n",
        "            \"temperature\": load_iot_data(\"temperature\", limit),\n",
        "            \"humidity\": load_iot_data(\"humidity\", limit),\n",
        "            \"soil\": load_iot_data(\"soil\", limit),\n",
        "        }\n",
        "\n",
        "        if all(df is None or df.empty for df in dfs.values()):\n",
        "            return \"No data available to generate a report.\", None\n",
        "\n",
        "        out_path = create_docx_report(dfs, limit)\n",
        "        return \"‚úÖ Report generated successfully. Download below:\", out_path\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error generating report: {str(e)}\", None\n"
      ],
      "metadata": {
        "id": "D4xGuzaSNQXh"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ TAB 3 GUI - üìÑ Generate Report"
      ],
      "metadata": {
        "id": "pVEFwcIVNtzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- TAB: Generate Report (GUI) ----------\n",
        "\n",
        "def build_generate_report_tab():\n",
        "    gr.Markdown(\"## üìÑ Generate Report\")\n",
        "    gr.Markdown(\n",
        "        \"Generate a Word (DOCX) report based on sensor data: temperature, humidity, and soil moisture.\"\n",
        "    )\n",
        "\n",
        "    report_samples = gr.Slider(\n",
        "        minimum=5,\n",
        "        maximum=200,\n",
        "        value=20,\n",
        "        step=1,\n",
        "        label=\"Number of samples per sensor\"\n",
        "    )\n",
        "\n",
        "    report_btn = gr.Button(\"üì• Generate & Download Report\", variant=\"primary\")\n",
        "    report_status = gr.Textbox(label=\"Status\", lines=2)\n",
        "    report_file = gr.File(label=\"Download DOCX\")\n",
        "\n",
        "    report_btn.click(\n",
        "        fn=generate_report_screen,\n",
        "        inputs=[report_samples],\n",
        "        outputs=[report_status, report_file]\n",
        "    )"
      ],
      "metadata": {
        "id": "8ElkHtUANx4I"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TAB 4 LOGIC - üñºÔ∏è Plant Disease Detection"
      ],
      "metadata": {
        "id": "5U06h9U6aiNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_plant(image, temp, humidity, soil):\n",
        "    preds = clf(image)\n",
        "    top = preds[0]\n",
        "\n",
        "    label = top[\"label\"]\n",
        "    score = top[\"score\"]\n",
        "\n",
        "    alerts = []\n",
        "    advice = []\n",
        "\n",
        "    # --- Conditions based on sensors / user input ---\n",
        "    if soil < 25:\n",
        "        alerts.append(\"Low soil moisture\")\n",
        "        advice.append(\"Recommendation: irrigate / water the plant\")\n",
        "\n",
        "    if humidity > 80:\n",
        "        alerts.append(\"High humidity\")\n",
        "        advice.append(\"Recommendation: improve ventilation (reduce fungal risk)\")\n",
        "\n",
        "    if temp > 40:\n",
        "        alerts.append(\"High temperature\")\n",
        "        advice.append(\"Recommendation: move the plant to a shaded area\")\n",
        "\n",
        "    # --- Color status (\"flag\") based on image prediction ---\n",
        "    # Simple rule: if label contains \"healthy\" => good (green), else bad (red)\n",
        "    is_bad = (\"healthy\" not in label.lower())\n",
        "\n",
        "    status_html = (\n",
        "        \"<div style='padding:10px;border-radius:10px;\"\n",
        "        f\"background:{'#ffdddd' if is_bad else '#ddffdd'};\"\n",
        "        f\"border:1px solid {'#ff0000' if is_bad else '#00aa00'};\"\n",
        "        \"font-weight:700;'>\"\n",
        "        f\"{'üî¥ Plant status: BAD' if is_bad else 'üü¢ Plant status: GOOD'}\"\n",
        "        \"</div>\"\n",
        "    )\n",
        "\n",
        "    if not alerts:\n",
        "        alerts.append(\"Status looks normal\")\n",
        "\n",
        "    return (\n",
        "        f\"Detected disease: {label} ({score:.2%})\",\n",
        "        status_html,\n",
        "        \"\\n\".join(alerts),\n",
        "        \"\\n\".join(advice)\n",
        "    )"
      ],
      "metadata": {
        "id": "H5KpoVVMbX8P"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TAB 4 GUI - üñºÔ∏è Plant Disease Detection"
      ],
      "metadata": {
        "id": "PZTNbJe1amWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_plant_disease_detection_tab():\n",
        "    gr.Markdown(\"## üñºÔ∏è Plant Disease Detection\")\n",
        "\n",
        "    with gr.Row():\n",
        "\n",
        "        # -------- LEFT SIDE --------\n",
        "        with gr.Column(scale=2):\n",
        "\n",
        "            image = gr.Image(\n",
        "                type=\"filepath\",\n",
        "                label=\"Upload plant image\",\n",
        "                sources=[\"upload\"]\n",
        "            )\n",
        "\n",
        "            temp = gr.Slider(0, 45, value=25, label=\"Temperature (¬∞C)\")\n",
        "            humidity = gr.Slider(0, 100, value=50, label=\"Humidity (%)\")\n",
        "            soil = gr.Slider(0, 100, value=50, label=\"Soil Moisture (%)\")\n",
        "\n",
        "            run_btn = gr.Button(\"Analyze Plant\", variant=\"primary\")\n",
        "\n",
        "        # -------- RIGHT SIDE --------\n",
        "        with gr.Column(scale=2):\n",
        "\n",
        "            diagnosis = gr.Textbox(\n",
        "                label=\"Diagnosis\",\n",
        "                placeholder=\"Plant disease diagnosis will appear here\"\n",
        "            )\n",
        "\n",
        "            status = gr.HTML(label=\"Status\")\n",
        "\n",
        "            alerts = gr.Textbox(\n",
        "                label=\"Alerts\",\n",
        "                lines=5,\n",
        "                placeholder=\"Sensor alerts and warnings will appear here\"\n",
        "            )\n",
        "\n",
        "            recommendations = gr.Textbox(\n",
        "                label=\"Recommendations\",\n",
        "                lines=5,\n",
        "                placeholder=\"Care and treatment recommendations will appear here\"\n",
        "            )\n",
        "\n",
        "    run_btn.click(\n",
        "        fn=analyze_plant,\n",
        "        inputs=[image, temp, humidity, soil],\n",
        "        outputs=[diagnosis, status, alerts, recommendations]\n",
        "    )"
      ],
      "metadata": {
        "id": "yt5-ZORrbbt9"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TAB 5 LOGIC - RAG Chat"
      ],
      "metadata": {
        "id": "xkSvfBItbI0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DOC_URLS = [\n",
        "    \"https://doi.org/10.1038/s41598-025-20629-y\",\n",
        "    \"https://doi.org/10.3389/fpls.2016.01419\",\n",
        "    \"https://doi.org/10.1038/s41598-025-05102-0\",\n",
        "    \"https://doi.org/10.1038/s41598-025-04758-y\",\n",
        "    \"https://doi.org/10.2174/0118743315321139240627092707\",\n",
        "]"
      ],
      "metadata": {
        "id": "1Xg6U8P7bHTm"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell 3: HTTP / Session setup\n",
        "# =========================\n",
        "# Purpose: Shared HTTP session + helper functions to fetch HTML/PDF and query academic APIs (Semantic Scholar/OpenAlex/Unpaywall).\n",
        "\n",
        "# Reuse a single session for performance and consistent headers/cookies.\n",
        "session = requests.Session()\n",
        "\n",
        "# Browser-like headers to improve compatibility with some sites.\n",
        "BROWSER_HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "}\n",
        "\n",
        "# Normalize DOI input (accept DOI or doi.org URL).\n",
        "def _normalize_doi(doi_or_url: str) -> str:\n",
        "    s = (doi_or_url or \"\").strip()\n",
        "    s = s.replace(\"https://doi.org/\", \"\").replace(\"http://doi.org/\", \"\")\n",
        "    return s.strip()\n",
        "\n",
        "# Fetch HTML and return (html_text, final_url, status_code).\n",
        "def fetch_html(url: str, timeout: int = 25):\n",
        "    r = session.get(url, headers={**BROWSER_HEADERS, \"Accept\": \"text/html,*/*;q=0.8\"}, timeout=timeout, allow_redirects=True)\n",
        "    return (r.text or \"\"), r.url, r.status_code\n",
        "\n",
        "# Extract readable main text from HTML (title/description/body).\n",
        "def extract_main_text_from_html(html: str) -> str:\n",
        "    try:\n",
        "        from bs4 import BeautifulSoup\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Install bs4 + lxml: pip install beautifulsoup4 lxml\")\n",
        "\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "    for tag in soup([\"script\",\"style\",\"noscript\",\"svg\",\"iframe\"]):\n",
        "        tag.decompose()\n",
        "\n",
        "    root = soup.find(\"main\") or soup.find(\"article\") or soup\n",
        "\n",
        "    title = soup.title.string.strip() if soup.title and soup.title.string else \"\"\n",
        "    desc = \"\"\n",
        "    m = soup.find(\"meta\", attrs={\"name\":\"description\"})\n",
        "    if m and m.get(\"content\"):\n",
        "        desc = m[\"content\"].strip()\n",
        "\n",
        "    chunks = []\n",
        "    for el in root.find_all([\"h1\",\"h2\",\"h3\",\"p\",\"li\"]):\n",
        "        t = el.get_text(\" \", strip=True)\n",
        "        if t and len(t) >= 30:\n",
        "            chunks.append(t)\n",
        "\n",
        "    if len(chunks) < 3:\n",
        "        t = re.sub(r\"\\s+\", \" \", root.get_text(\" \", strip=True)).strip()\n",
        "        chunks = [t] if t else []\n",
        "\n",
        "    chunks = list(dict.fromkeys(chunks))\n",
        "    body = \"\\n\".join(chunks).strip()\n",
        "\n",
        "    parts = []\n",
        "    if title: parts.append(f\"TITLE: {title}\")\n",
        "    if desc:  parts.append(f\"DESCRIPTION: {desc}\")\n",
        "    if body:  parts.append(body)\n",
        "    return \"\\n\".join(parts).strip()\n",
        "\n",
        "\n",
        "# API lookup: Semantic Scholar (metadata + possible openAccessPdf).\n",
        "def semantic_scholar_lookup(doi: str):\n",
        "    \"\"\"Return dict with title/abstract and possibly openAccessPdf url.\"\"\"\n",
        "    # No key required for basic use, but rate-limited.\n",
        "    url = f\"https://api.semanticscholar.org/graph/v1/paper/DOI:{quote(doi, safe='')}\"\n",
        "    params = {\"fields\": \"title,abstract,openAccessPdf,url\"}\n",
        "    r = session.get(url, params=params, headers=BROWSER_HEADERS, timeout=25)\n",
        "    if r.status_code != 200:\n",
        "        return None\n",
        "    return r.json()\n",
        "\n",
        "# API lookup: OpenAlex (metadata + locations + inverted-index abstract).\n",
        "def openalex_lookup(doi: str):\n",
        "    url = f\"https://api.openalex.org/works/doi:{quote(doi, safe='')}\"\n",
        "    r = session.get(url, headers=BROWSER_HEADERS, timeout=25)\n",
        "    if r.status_code != 200:\n",
        "        return None\n",
        "    return r.json()\n",
        "\n",
        "# API lookup: Unpaywall (OA locations; requires email parameter).\n",
        "def unpaywall_lookup(doi: str, email: str = \"test@example.com\"):\n",
        "    # Unpaywall requires an email parameter (your real email is best).\n",
        "    url = f\"https://api.unpaywall.org/v2/{quote(doi, safe='')}\"\n",
        "    r = session.get(url, params={\"email\": email}, headers=BROWSER_HEADERS, timeout=25)\n",
        "    if r.status_code != 200:\n",
        "        return None\n",
        "    return r.json()\n",
        "\n",
        "# Select the best PDF URL from available sources (Semantic Scholar/OpenAlex/Unpaywall).\n",
        "def _pick_pdf_url_from_sources(ss=None, oa=None, up=None) -> str:\n",
        "    # 1) Semantic Scholar openAccessPdf\n",
        "    if ss and isinstance(ss, dict):\n",
        "        oap = ss.get(\"openAccessPdf\") or {}\n",
        "        if isinstance(oap, dict) and oap.get(\"url\"):\n",
        "            return oap[\"url\"]\n",
        "\n",
        "    # 2) OpenAlex primary_location / open_access\n",
        "    if oa and isinstance(oa, dict):\n",
        "        pl = oa.get(\"primary_location\") or {}\n",
        "        if isinstance(pl, dict):\n",
        "            pdf = pl.get(\"pdf_url\")\n",
        "            if pdf: return pdf\n",
        "            landing = pl.get(\"landing_page_url\")\n",
        "            if landing and landing.lower().endswith(\".pdf\"):\n",
        "                return landing\n",
        "        oa2 = oa.get(\"open_access\") or {}\n",
        "        if isinstance(oa2, dict):\n",
        "            oa_url = oa2.get(\"oa_url\")\n",
        "            if oa_url and oa_url.lower().endswith(\".pdf\"):\n",
        "                return oa_url\n",
        "\n",
        "    # 3) Unpaywall best_oa_location\n",
        "    if up and isinstance(up, dict):\n",
        "        bol = up.get(\"best_oa_location\") or {}\n",
        "        if isinstance(bol, dict):\n",
        "            pdf = bol.get(\"url_for_pdf\")\n",
        "            if pdf: return pdf\n",
        "            url = bol.get(\"url\")\n",
        "            if url and url.lower().endswith(\".pdf\"):\n",
        "                return url\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "# Download a PDF and extract text from the first pages (bounded by max_pages).\n",
        "def extract_text_from_pdf_url(pdf_url: str, max_pages: int = 8) -> str:\n",
        "    \"\"\"Download PDF and extract text from first max_pages pages.\"\"\"\n",
        "    # Try pypdf first (often installed). Fallback to pdfminer if needed.\n",
        "    r = session.get(pdf_url, headers={**BROWSER_HEADERS, \"Accept\":\"application/pdf,*/*;q=0.8\"}, timeout=40, allow_redirects=True)\n",
        "    if r.status_code != 200 or not r.content:\n",
        "        return \"\"\n",
        "\n",
        "    data = r.content\n",
        "\n",
        "    # pypdf\n",
        "    try:\n",
        "        from pypdf import PdfReader\n",
        "        import io\n",
        "        reader = PdfReader(io.BytesIO(data))\n",
        "        out = []\n",
        "        n = min(len(reader.pages), max_pages)\n",
        "        for i in range(n):\n",
        "            out.append(reader.pages[i].extract_text() or \"\")\n",
        "        text = \"\\n\".join(out).strip()\n",
        "        text = re.sub(r\"\\s+\", \" \", text)\n",
        "        return text.strip()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # pdfminer\n",
        "    try:\n",
        "        from pdfminer.high_level import extract_text\n",
        "        import io\n",
        "        text = extract_text(io.BytesIO(data), maxpages=max_pages) or \"\"\n",
        "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "        return text\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "# Utility: reconstruct OpenAlex inverted-index abstract into ordered text.\n",
        "def _reconstruct_abstract_from_inverted_index(inv: dict) -> str:\n",
        "    \"\"\"\n",
        "    OpenAlex returns abstracts as an inverted index:\n",
        "    {word: [pos1, pos2, ...], ...}\n",
        "    This reconstructs the abstract text in the correct order.\n",
        "    \"\"\"\n",
        "    if not isinstance(inv, dict) or not inv:\n",
        "        return \"\"\n",
        "\n",
        "    # Find max position to size the token list\n",
        "    max_pos = -1\n",
        "    for positions in inv.values():\n",
        "        if isinstance(positions, list) and positions:\n",
        "            mp = max(positions)\n",
        "            if mp > max_pos:\n",
        "                max_pos = mp\n",
        "\n",
        "    if max_pos < 0:\n",
        "        return \"\"\n",
        "\n",
        "    tokens = [\"\"] * (max_pos + 1)\n",
        "\n",
        "    for word, positions in inv.items():\n",
        "        if not isinstance(positions, list):\n",
        "            continue\n",
        "        for p in positions:\n",
        "            if isinstance(p, int) and 0 <= p < len(tokens):\n",
        "                tokens[p] = word\n",
        "\n",
        "    # Join; remove empties\n",
        "    text = \" \".join(t for t in tokens if t)\n",
        "    return text.strip()\n"
      ],
      "metadata": {
        "id": "AWKeK8JEcfJL"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4. DOI Metadata fallback (only if HTML is short)\n",
        "# =========================\n",
        "# Purpose: Fetch usable document text from a URL with fallbacks:\n",
        "# HTML -> Open-Access PDF (via APIs) -> Abstract metadata -> Title-only.\n",
        "\n",
        "\n",
        "def get_document_text(url: str, min_chars: int = 800, unpaywall_email: str = \"test@example.com\", debug: bool = False) -> str:\n",
        "    \"\"\"\n",
        "    Returns the best available text we can legally obtain.\n",
        "    Order:\n",
        "      1) HTML extraction (if enough)\n",
        "      2) OA PDF extraction via Semantic Scholar / OpenAlex / Unpaywall (if available)\n",
        "      3) Abstract via Semantic Scholar/OpenAlex (fallback)\n",
        "      4) Title only\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Try extracting text directly from the landing HTML page.\n",
        "    html, final_url, status = fetch_html(url)\n",
        "    text_html = extract_main_text_from_html(html) if html else \"\"\n",
        "\n",
        "    # Optional debug printing for tracing which path is used.\n",
        "    if debug:\n",
        "        print(\"final_url:\", final_url)\n",
        "        print(\"html_status:\", status, \"| html_text_chars:\", len(text_html))\n",
        "\n",
        "    # If HTML content is sufficient, return it immediately.\n",
        "    if len(text_html) >= min_chars:\n",
        "        return text_html\n",
        "\n",
        "    # 2) If input is a DOI link, try Open-Access routes (PDF).\n",
        "    doi = _normalize_doi(url) if \"doi.org/\" in (url or \"\") else \"\"\n",
        "    ss = oa = up = None\n",
        "\n",
        "    if doi:\n",
        "        # Query multiple services to maximize chances of finding an OA PDF.\n",
        "        try:\n",
        "            ss = semantic_scholar_lookup(doi)\n",
        "        except Exception:\n",
        "            ss = None\n",
        "        try:\n",
        "            oa = openalex_lookup(doi)\n",
        "        except Exception:\n",
        "            oa = None\n",
        "        try:\n",
        "            up = unpaywall_lookup(doi, email=unpaywall_email)\n",
        "        except Exception:\n",
        "            up = None\n",
        "\n",
        "        # Pick the best PDF URL from the available sources (if any).\n",
        "        pdf_url = _pick_pdf_url_from_sources(ss=ss, oa=oa, up=up)\n",
        "        if debug:\n",
        "            print(\"pdf_url:\", pdf_url or \"(none)\")\n",
        "\n",
        "        # If we found a PDF, extract text from the first pages.\n",
        "        if pdf_url:\n",
        "            pdf_text = extract_text_from_pdf_url(pdf_url, max_pages=8)\n",
        "            if debug:\n",
        "                print(\"pdf_text_chars:\", len(pdf_text))\n",
        "            if len(pdf_text) >= min_chars:\n",
        "                # Optionally prepend a title header when available.\n",
        "                title = (ss or {}).get(\"title\") or (oa or {}).get(\"title\") or \"\"\n",
        "                title = title.get(\"display_name\") if isinstance(title, dict) else title\n",
        "                header = f\"TITLE: {title}\".strip() if title else \"\"\n",
        "                return (header + \"\\n\" + pdf_text).strip()\n",
        "\n",
        "        # 3) If PDF is missing/short, fall back to abstract metadata (when present).\n",
        "        title = \"\"\n",
        "        abstract = \"\"\n",
        "\n",
        "        if ss and isinstance(ss, dict):\n",
        "            title = (ss.get(\"title\") or \"\").strip()\n",
        "            abstract = (ss.get(\"abstract\") or \"\").strip()\n",
        "\n",
        "        if (not abstract) and oa and isinstance(oa, dict):\n",
        "            t = oa.get(\"title\") or \"\"\n",
        "            title = title or t\n",
        "            # OpenAlex abstract can be stored as an inverted index.\n",
        "            inv = oa.get(\"abstract_inverted_index\")\n",
        "            if inv:\n",
        "                abstract = _reconstruct_abstract_from_inverted_index(inv)\n",
        "\n",
        "        # Return any metadata we managed to obtain.\n",
        "        if title or abstract:\n",
        "            parts = []\n",
        "            if title: parts.append(f\"TITLE: {title}\")\n",
        "            if abstract: parts.append(f\"ABSTRACT: {abstract}\")\n",
        "            return \"\\n\".join(parts).strip()\n",
        "\n",
        "    # 4) Last resort: return thin HTML (title/description) if present.\n",
        "    if text_html:\n",
        "        return text_html.strip()\n",
        "\n",
        "    # Final fallback: return the URL as a minimal title marker.\n",
        "    return f\"TITLE: {url}\".strip()"
      ],
      "metadata": {
        "id": "gtNn87uDcpAW"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 5. NLP Preprocessing\n",
        "# =========================\n",
        "# Purpose: Standardize text into comparable tokens for indexing/search.\n",
        "# Pipeline: tokenize -> stopword removal -> stemming.\n",
        "\n",
        "def tokenize(text):\n",
        "    \"\"\"Convert text to a list of lowercase word tokens.\"\"\"\n",
        "    return re.findall(r\"\\w+\", (text or \"\").lower())\n",
        "\n",
        "def remove_stopwords(tokens, stop_words):\n",
        "    \"\"\"Remove stop words from a list of tokens.\"\"\"\n",
        "    return [t for t in tokens if t not in stop_words]\n",
        "\n",
        "def apply_stemming(tokens):\n",
        "    \"\"\"Apply Porter stemming to a list of tokens.\"\"\"\n",
        "    return [stemmer.stem(t) for t in tokens]\n",
        "\n",
        "\n",
        "def preprocess_query(query: str):\n",
        "    # Goal: Apply the same normalization steps used for documents to the user query.\n",
        "    tokens = tokenize(query)\n",
        "    tokens = remove_stopwords(tokens, stop_words)\n",
        "    tokens = apply_stemming(tokens)\n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "sN9YEitTctBm"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 6. Document Text Access\n",
        "# =========================\n",
        "# Purpose: Fetch and store raw text for each document URL so it can be indexed later.\n",
        "# Output: doc_text dict mapping doc_id -> extracted text (may be empty on failure).\n",
        "\n",
        "def build_doc_text_map(doc_urls, min_chars=800, unpaywall_email=\"test@example.com\", debug=False):\n",
        "    doc_text = {}\n",
        "    for i, url in enumerate(doc_urls):\n",
        "        # Try to extract the best available text (HTML/PDF/abstract fallback).\n",
        "        try:\n",
        "            doc_text[i] = get_document_text(\n",
        "                url,\n",
        "                min_chars=min_chars,\n",
        "                unpaywall_email=unpaywall_email,\n",
        "                debug=debug\n",
        "            ) or \"\"\n",
        "        except Exception as e:\n",
        "            # Keep the pipeline running even if a document fails to fetch.\n",
        "            print(f\"Failed to fetch document {i}: {e}\")\n",
        "            doc_text[i] = \"\"\n",
        "    return doc_text\n",
        "\n",
        "\n",
        "# Placeholder / initialization for the document-text mapping (doc_id -> text).\n",
        "doc_text = {}\n"
      ],
      "metadata": {
        "id": "PnI_A-yScy4j"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 7. Index Construction\n",
        "# =========================\n",
        "# Purpose: Build an inverted index for fast keyword-based retrieval.\n",
        "# - Input: raw document texts (doc_text) and preprocessing settings (stop_words).\n",
        "# - Output:\n",
        "#   1) inverted: term -> list of doc_ids containing the term\n",
        "#   2) doc_map: doc_id -> original URL\n",
        "\n",
        "def build_inverted_index(urls, stop_words, doc_text):\n",
        "    inverted = defaultdict(set)  # term -> set(doc_ids)\n",
        "    doc_map = {i: url for i, url in enumerate(urls)}  # DocID -> URL\n",
        "\n",
        "    for doc_id in range(len(urls)):\n",
        "        # Get the stored text for this document (support int or string keys).\n",
        "        text = doc_text.get(doc_id) or doc_text.get(str(doc_id)) or \"\"\n",
        "\n",
        "        # Normalize document text into searchable terms.\n",
        "        tokens = tokenize(text)\n",
        "        tokens = remove_stopwords(tokens, stop_words)\n",
        "        tokens = apply_stemming(tokens)\n",
        "\n",
        "        # Add each unique term to the index for this document.\n",
        "        for term in set(tokens):\n",
        "            inverted[term].add(doc_id)\n",
        "\n",
        "    # Convert sets to sorted lists for stable output/serialization.\n",
        "    inverted = {term: sorted(list(ids)) for term, ids in inverted.items()}\n",
        "    return inverted, doc_map\n"
      ],
      "metadata": {
        "id": "qQYDi7e4c0oG"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 8. Firebase I/O\n",
        "# =========================\n",
        "# Purpose: Persist and reuse the document store in Firebase.\n",
        "# Stored objects:\n",
        "# - doc_text: doc_id -> extracted text\n",
        "# - public_index: inverted index (term -> doc_ids)\n",
        "# - doc_map: doc_id -> source URL\n",
        "\n",
        "def save_to_firebase(data, path):\n",
        "    # Write JSON data to a Firebase Realtime Database path using HTTP PUT.\n",
        "    base = FIREBASE_URL.rstrip(\"/\")\n",
        "    url = f\"{base}/{path}.json\"\n",
        "    r = requests.put(url, json=data, timeout=30)\n",
        "    print(\"PUT\", path, \"status:\", r.status_code, \"| resp:\", r.text[:200])\n",
        "    if r.status_code != 200:\n",
        "        raise RuntimeError(f\"PUT {path} failed: {r.status_code} | {r.text[:400]}\")\n",
        "    return r.status_code, r.text\n",
        "\n",
        "\n",
        "def firebase_get(path):\n",
        "    # Read JSON data from a Firebase Realtime Database path using HTTP GET.\n",
        "    base = FIREBASE_URL.rstrip(\"/\")\n",
        "    url = f\"{base}/{path}.json\"\n",
        "    r = requests.get(url, timeout=30)\n",
        "    print(\"GET\", path, \"status:\", r.status_code, \"| resp:\", r.text[:200])\n",
        "    if r.status_code != 200:\n",
        "        raise RuntimeError(f\"GET {path} failed: {r.status_code} | {r.text[:400]}\")\n",
        "    return r.json()\n",
        "\n",
        "\n",
        "def build_and_save_index(\n",
        "    urls,\n",
        "    stop_words,\n",
        "    index_path=\"indexes/public_index\",\n",
        "    map_path=\"indexes/doc_map\",\n",
        "    text_path=\"indexes/doc_text\"):\n",
        "    # Orchestrator: build doc_text + inverted index locally, then save all artifacts to Firebase.\n",
        "\n",
        "    # 1) Build doc_text locally\n",
        "    doc_text_local = build_doc_text_map(urls)\n",
        "\n",
        "    # Save doc_text with string keys (JSON consistency)\n",
        "    doc_text_to_save = {str(k): v for k, v in doc_text_local.items()}\n",
        "    save_to_firebase(doc_text_to_save, text_path)\n",
        "    print(\"‚úÖ doc_text saved\")\n",
        "\n",
        "    # 2) Build index + doc_map using doc_text_local\n",
        "    inv_index, doc_map = build_inverted_index(urls, stop_words, doc_text_local)\n",
        "\n",
        "    # Save doc_map with string keys\n",
        "    doc_map_json = {str(k): v for k, v in doc_map.items()}\n",
        "    save_to_firebase(inv_index, index_path)\n",
        "    print(\"‚úÖ index saved\")\n",
        "\n",
        "    save_to_firebase(doc_map_json, map_path)\n",
        "    print(\"‚úÖ doc_map saved\")\n",
        "\n",
        "    return inv_index, doc_map_json, doc_text_local\n",
        "\n",
        "# Load existing store from Firebase if present; otherwise build once and save.\n",
        "existing_index = firebase_get(\"indexes/public_index\")  # None if missing\n",
        "existing_map   = firebase_get(\"indexes/doc_map\")\n",
        "existing_text  = firebase_get(\"indexes/doc_text\")\n",
        "\n",
        "if existing_index is not None and existing_map is not None and existing_text is not None:\n",
        "    # Reuse cached data to avoid rebuilding/re-fetching documents.\n",
        "    inv_index = existing_index\n",
        "    doc_map_json = existing_map\n",
        "    doc_text_local = existing_text\n",
        "    print(\"‚úÖ Loaded existing store from Firebase (no rebuild).\")\n",
        "else:\n",
        "    # First-time setup: build and persist the store.\n",
        "    inv_index, doc_map_json, doc_text_local = build_and_save_index(DOC_URLS, stop_words)\n",
        "    print(\"‚úÖ Built and saved store to Firebase.\")\n",
        "\n",
        "# Expose globals used by retrieval/search code.\n",
        "public_index = inv_index\n",
        "doc_map = doc_map_json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpwLmT6Fc9BT",
        "outputId": "3aef67e4-373c-42ea-907a-bbebf82b6093"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GET indexes/public_index status: 200 | resp: {\"0\":[0,1,2,3,4],\"00\":[2],\"000\":[0,4],\"1\":[0,1,2,3,4],\"01\":[0,1,2,3],\"0001\":[2,3,4],\"2\":[0,1,2,3,4],\"02\":[0],\"002\":[1],\"3\":[0,1,2,3,4],\"03\":[1],\"003\":[1],\"4\":[0,1,2,3,4],\"04\":[2],\"004\":[1],\"5\":[0,1,2,\n",
            "GET indexes/doc_map status: 200 | resp: [\"https://doi.org/10.1038/s41598-025-20629-y\",\"https://doi.org/10.3389/fpls.2016.01419\",\"https://doi.org/10.1038/s41598-025-05102-0\",\"https://doi.org/10.1038/s41598-025-04758-y\",\"https://doi.org/10.21\n",
            "GET indexes/doc_text status: 200 | resp: [\"TITLE: Medicinal plant leaf disease classification using optimal weighted features with dilated adaptive DenseNet and attention mechanism | Scientific Reports\\nDESCRIPTION: The agriculture sector pl\n",
            "‚úÖ Loaded existing store from Firebase (no rebuild).\n",
            "GET indexes/public_index status: 200 | resp: {\"0\":[0,1,2,3,4],\"00\":[2],\"000\":[0,4],\"1\":[0,1,2,3,4],\"01\":[0,1,2,3],\"0001\":[2,3,4],\"2\":[0,1,2,3,4],\"02\":[0],\"002\":[1],\"3\":[0,1,2,3,4],\"03\":[1],\"003\":[1],\"4\":[0,1,2,3,4],\"04\":[2],\"004\":[1],\"5\":[0,1,2,\n",
            "GET indexes/doc_map status: 200 | resp: [\"https://doi.org/10.1038/s41598-025-20629-y\",\"https://doi.org/10.3389/fpls.2016.01419\",\"https://doi.org/10.1038/s41598-025-05102-0\",\"https://doi.org/10.1038/s41598-025-04758-y\",\"https://doi.org/10.21\n",
            "GET indexes/doc_text status: 200 | resp: [\"TITLE: Medicinal plant leaf disease classification using optimal weighted features with dilated adaptive DenseNet and attention mechanism | Scientific Reports\\nDESCRIPTION: The agriculture sector pl\n",
            "‚úÖ Loaded existing store from Firebase (no rebuild).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 9 Load store from Firebase\n",
        "# =========================\n",
        "# Purpose: Load previously saved index artifacts from Firebase into runtime globals.\n",
        "# Loads: public_index (inverted index), doc_map (doc_id -> URL), and optionally doc_text.\n",
        "\n",
        "INDEX_PATH = \"indexes/public_index\"\n",
        "MAP_PATH   = \"indexes/doc_map\"\n",
        "TEXT_PATH  = \"indexes/doc_text\"\n",
        "\n",
        "public_index = None\n",
        "doc_map = None\n",
        "doc_text = None\n",
        "\n",
        "def load_store_from_firebase(load_text: bool = False):\n",
        "    # Load index + doc_map from Firebase into globals\n",
        "    global public_index, doc_map, doc_text\n",
        "\n",
        "    # Always load index and doc_map (use empty dict if missing).\n",
        "    public_index = firebase_get(INDEX_PATH) or {}\n",
        "    doc_map = firebase_get(MAP_PATH) or {}\n",
        "\n",
        "    # Normalize doc_map shape if Firebase returns a JSON array instead of an object.\n",
        "    if isinstance(doc_map, list):\n",
        "      doc_map = {str(i): v for i, v in enumerate(doc_map)}\n",
        "\n",
        "    # Optionally load the full document texts (can be large).\n",
        "    if load_text:\n",
        "        doc_text = firebase_get(TEXT_PATH) or {}\n",
        "\n",
        "    # Basic summary for quick sanity-check.\n",
        "    print(\"Loaded:\",\n",
        "          \"terms=\", len(public_index),\n",
        "          \"| docs=\", len(doc_map) if hasattr(doc_map, \"__len__\") else type(doc_map))\n",
        "\n",
        "    return public_index, doc_map, doc_text\n"
      ],
      "metadata": {
        "id": "Ymnru7rrdERK"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 10. Retrieval (uses data loaded from Firebase)\n",
        "# =========================\n",
        "# Purpose: Perform simple keyword-based retrieval using the inverted index.\n",
        "# Method: preprocess query -> count matching terms per document -> return top-k docs.\n",
        "\n",
        "def search_top_k(query: str, k: int = 3):\n",
        "    # Ensure index and doc_map are available in memory (load if missing).\n",
        "    if public_index is None or doc_map is None:\n",
        "        load_store_from_firebase(load_text=False)\n",
        "\n",
        "    # Convert the raw query into normalized terms (tokenize/stopwords/stemming).\n",
        "    q_terms = preprocess_query(query)\n",
        "    scores = defaultdict(int)\n",
        "\n",
        "    # Score documents by how many query terms they contain.\n",
        "    for term in q_terms:\n",
        "        for doc_id in (public_index.get(term, []) or []):\n",
        "            scores[int(doc_id)] += 1\n",
        "\n",
        "    # Rank by score and keep the top-k.\n",
        "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:k]\n",
        "\n",
        "    # Build a compact result list with doc id, score, and source URL.\n",
        "    results = []\n",
        "    for doc_id, score in ranked:\n",
        "        url = doc_map.get(str(doc_id)) if isinstance(doc_map, dict) else None\n",
        "        results.append({\"doc_id\": doc_id, \"score\": score, \"url\": url})\n",
        "\n",
        "    return q_terms, results\n"
      ],
      "metadata": {
        "id": "yRF_hY27dKdi"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 11. RAG ‚Äì Generation (AI)\n",
        "# =========================\n",
        "# Purpose: Combine retrieval (inverted index) with optional text generation to answer questions using retrieved context.\n",
        "\n",
        "# Per-document cache to avoid repeated Firebase GETs\n",
        "_doc_text_cache = {}\n",
        "\n",
        "def get_doc_text(doc_id: int) -> str:\n",
        "    \"\"\"\n",
        "    Fetch a single document's text from Firebase (Realtime DB) at:\n",
        "    indexes/doc_text/<doc_id>\n",
        "    Uses a small in-memory cache for speed.\n",
        "    \"\"\"\n",
        "    # Normalize doc_id to a stable Firebase key.\n",
        "    key = str(int(doc_id))\n",
        "\n",
        "    # Return from cache if available.\n",
        "    if key in _doc_text_cache:\n",
        "        return _doc_text_cache[key] or \"\"\n",
        "\n",
        "    # Determine base path for document texts (fallback if TEXT_PATH is missing).\n",
        "    text_base = globals().get(\"TEXT_PATH\", \"indexes/doc_text\")\n",
        "\n",
        "    # Fetch only this document's text from Firebase.\n",
        "    try:\n",
        "        txt = firebase_get(f\"{text_base}/{key}\")\n",
        "    except Exception:\n",
        "        txt = \"\"\n",
        "\n",
        "    # Normalize missing/None responses.\n",
        "    if txt is None:\n",
        "        txt = \"\"\n",
        "\n",
        "    # Ensure the return type is always a string.\n",
        "    if not isinstance(txt, str):\n",
        "        txt = str(txt)\n",
        "\n",
        "    # Cache the result to reduce future Firebase calls.\n",
        "    _doc_text_cache[key] = txt\n",
        "    return txt\n",
        "\n",
        "\n",
        "# Try to load a local HuggingFace generation model; otherwise use a non-LLM fallback.\n",
        "try:\n",
        "    from transformers import pipeline\n",
        "    _GEN_AVAILABLE = True\n",
        "except Exception as e:\n",
        "    _GEN_AVAILABLE = False\n",
        "    _GEN_ERR = e\n",
        "\n",
        "gen = None\n",
        "if _GEN_AVAILABLE:\n",
        "    try:\n",
        "        gen = pipeline(\n",
        "            \"text2text-generation\",\n",
        "            model=\"google/flan-t5-large\",\n",
        "            max_new_tokens=220\n",
        "        )\n",
        "    except Exception:\n",
        "        # Fallback to a smaller model if the large one cannot be loaded.\n",
        "        try:\n",
        "            gen = pipeline(\n",
        "                \"text2text-generation\",\n",
        "                model=\"google/flan-t5-base\",\n",
        "                max_new_tokens=220\n",
        "            )\n",
        "        except Exception as e:\n",
        "            gen = None\n",
        "            _GEN_ERR = e\n",
        "\n",
        "\n",
        "def _build_context(results, snippet_chars: int = 1200) -> str:\n",
        "    # Build a single context string by concatenating top retrieved document snippets.\n",
        "    parts = []\n",
        "    for r in results:\n",
        "        doc_id = r[\"doc_id\"]\n",
        "        url = r.get(\"url\")\n",
        "        text = (get_doc_text(doc_id) or \"\")[:snippet_chars]\n",
        "        parts.append(f\"[Doc {doc_id}] {url}\\n{text}\")\n",
        "    return \"\\n\\n---\\n\\n\".join(parts)\n",
        "\n",
        "\n",
        "def _fallback_answer(query: str, results, snippet_chars: int = 700) -> str:\n",
        "    # If no generation model is available, return retrieved snippets as a proof of retrieval.\n",
        "    lines = [\"(No generation model loaded. Showing retrieved snippets.)\\n\"]\n",
        "    lines.append(f\"Question: {query}\\n\")\n",
        "    for r in results:\n",
        "        doc_id = r[\"doc_id\"]\n",
        "        url = r.get(\"url\")\n",
        "        text = (get_doc_text(doc_id) or \"\")[:snippet_chars]\n",
        "        lines.append(f\"[Doc {doc_id}] {url}\\n{text}\\n\")\n",
        "    return \"\\n---\\n\".join(lines)\n",
        "\n",
        "\n",
        "def rag_generate_answer(query: str, k: int = 3, snippet_chars: int = 1200):\n",
        "    # Pipeline: retrieve top-k -> build context -> generate answer (or fallback).\n",
        "    q_terms, results = search_top_k(query, k)\n",
        "\n",
        "    if not results:\n",
        "        return q_terms, results, \"No documents matched the query terms.\"\n",
        "\n",
        "    context = _build_context(results, snippet_chars=snippet_chars)\n",
        "\n",
        "    # If generator is unavailable, return an extractive-style fallback.\n",
        "    if gen is None:\n",
        "        return q_terms, results, _fallback_answer(query, results)\n",
        "\n",
        "    # Prompt the model to answer using only the provided context and include doc citations.\n",
        "    prompt = f\"\"\"\n",
        "You are a helpful assistant. Answer the question ONLY using the provided context.\n",
        "If the context does not contain enough information, say: \"I don't have enough information.\"\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Answer (include citations like [Doc 0], [Doc 2]):\n",
        "\"\"\"\n",
        "    answer = gen(prompt, do_sample=False)[0][\"generated_text\"]\n",
        "    return q_terms, results, answer\n",
        "\n",
        "\n",
        "def rag_generate_answer_from_results(query: str, q_terms, results, snippet_chars: int = 1200):\n",
        "    # Same generation logic, but assumes retrieval was already done externally.\n",
        "    if not results:\n",
        "        return q_terms, results, \"No documents matched the query terms.\"\n",
        "\n",
        "    context = _build_context(results, snippet_chars=snippet_chars)\n",
        "\n",
        "    if gen is None:\n",
        "        return q_terms, results, _fallback_answer(query, results)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a helpful assistant. Answer the question ONLY using the provided context.\n",
        "If the context does not contain enough information, say: \"I don't have enough information.\"\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Answer (include citations like [Doc 0], [Doc 2]):\n",
        "\"\"\"\n",
        "    answer = gen(prompt, do_sample=False)[0][\"generated_text\"]\n",
        "    return q_terms, results, answer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2o5n47cdLRO",
        "outputId": "296b347e-4a9e-47a7-ab10-37b565a1e96b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 12. Presentation Layer\n",
        "# =========================\n",
        "# Purpose: Display retrieval results (top-k documents + snippets) and then print a RAG-generated answer.\n",
        "\n",
        "def show_retrieval_context(query: str, k: int = 3, snippet_chars: int = 700, gen_context_chars: int = 1200):\n",
        "    # Run retrieval to get processed query terms and ranked documents.\n",
        "    q_terms, results = search_top_k(query, k)\n",
        "\n",
        "    # Print a short summary of the query and preprocessing output.\n",
        "    print(\"Query:\", query)\n",
        "    print(\"Processed query terms:\", q_terms)\n",
        "    print(\"\\nTop retrieved documents:\\n\")\n",
        "\n",
        "    # Exit early if no documents matched any query terms.\n",
        "    if not results:\n",
        "        print(\"No documents matched the query terms.\")\n",
        "        return\n",
        "\n",
        "    # Print each retrieved document with its score and a short text preview.\n",
        "    for i, r in enumerate(results, 1):\n",
        "        doc_id = r[\"doc_id\"]\n",
        "        score  = r[\"score\"]\n",
        "        url    = r.get(\"url\")\n",
        "        text   = get_doc_text(doc_id)\n",
        "\n",
        "        print(f\"--- Document {i} ---\")\n",
        "        print(\"Doc ID:\", doc_id)\n",
        "        print(\"Score :\", score)\n",
        "        print(\"URL   :\", url)\n",
        "        print(\"Text snippet:\")\n",
        "        print((text or \"\")[:snippet_chars])\n",
        "        print()\n",
        "\n",
        "    # Generate and print a final answer using the retrieved results as context.\n",
        "    _, _, answer = rag_generate_answer_from_results(query, q_terms, results, snippet_chars=gen_context_chars)\n",
        "    print(\"=== RAG Answer ===\")\n",
        "    print(answer)\n"
      ],
      "metadata": {
        "id": "GDmVbDIzdSFr"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TAB 5 GUI - RAG Chat"
      ],
      "metadata": {
        "id": "qXsIyqVwdT-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 13. Query Screen GUI (Gradio)\n",
        "# =========================\n",
        "# Purpose: Provide a simple web UI to run queries against the index and show retrieval + RAG answer.\n",
        "# Behavior: On submit -> run rag_generate_answer -> display ranked docs table + generated answer.\n",
        "\n",
        "def build_rag_chat_tab():\n",
        "\n",
        "    gr.Markdown(\"## üí¨ RAG Chat\")\n",
        "    gr.Markdown(\"Type a query ‚Üí retrieve top-k documents ‚Üí generate an AI answer.\")\n",
        "\n",
        "    question = gr.Textbox(\n",
        "        label=\"üîç Query\",\n",
        "        placeholder=\"e.g., What are symptoms of bacterial wilt in tomato?\",\n",
        "        lines=2\n",
        "    )\n",
        "    n_results = gr.Slider(minimum=1, maximum=5, value=3, step=1, label=\"Top-K documents\")\n",
        "\n",
        "    run_btn = gr.Button(\"Run\", variant=\"primary\")\n",
        "\n",
        "    retrieved_df = gr.Dataframe(\n",
        "        headers=[\"doc_id\", \"score\", \"url\"],\n",
        "        label=\"üìÑ Retrieved documents (ranked)\",\n",
        "        wrap=True\n",
        "    )\n",
        "    answer_box = gr.Textbox(label=\"ü§ñ RAG Answer\", lines=12)\n",
        "\n",
        "    def ui_query_in_tab(q: str, k: int):\n",
        "        if not q or not q.strip():\n",
        "            return [], \"Please enter a question.\"\n",
        "\n",
        "        q_terms, results, answer = rag_generate_answer(q, k=int(k))\n",
        "\n",
        "        rows = []\n",
        "        for r in results:\n",
        "            rows.append([r.get(\"doc_id\"), r.get(\"score\"), r.get(\"url\")])\n",
        "\n",
        "        return rows, answer\n",
        "\n",
        "    run_btn.click(\n",
        "        fn=ui_query_in_tab,\n",
        "        inputs=[question, n_results],\n",
        "        outputs=[retrieved_df, answer_box]\n",
        "    )\n",
        "\n",
        "    question.submit(\n",
        "        fn=ui_query_in_tab,\n",
        "        inputs=[question, n_results],\n",
        "        outputs=[retrieved_df, answer_box]\n",
        "    )\n"
      ],
      "metadata": {
        "id": "YjpGYYp8dUSJ"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "FEj9G-EnMWTN"
      },
      "outputs": [],
      "source": [
        "def build_placeholder_tab(title: str, note: str = \"◊õ◊ê◊ü ◊ô◊ô◊õ◊†◊° ◊î◊ß◊ï◊ì ◊ë◊î◊û◊©◊ö\"):\n",
        "    gr.Markdown(f\"## {title}\")\n",
        "    gr.Markdown(note)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# TABS (EMPTY PLACEHOLDERS)\n",
        "# -----------------------------\n",
        "\n",
        "def build_iot_dashboard_tab():\n",
        "    \"\"\"Complete IoT Dashboard with all visualizations\"\"\"\n",
        "\n",
        "    gr.Markdown('### üìà Comprehensive Sensor Analytics')\n",
        "\n",
        "    refresh_btn = gr.Button('üîÑ Refresh All Data', variant='primary', size='lg')\n",
        "\n",
        "    # KPI Cards\n",
        "    gr.Markdown('#### üìå Current Readings')\n",
        "    kpi_html = gr.HTML()\n",
        "\n",
        "    # Statistics Cards\n",
        "    gr.Markdown('#### üìä Statistical Summary')\n",
        "    stats_html = gr.HTML()\n",
        "\n",
        "    # Main Time Series\n",
        "    gr.Markdown('#### üìà Time Series Overview')\n",
        "    ts_plot = gr.Plot()\n",
        "\n",
        "    # Correlation Analysis\n",
        "    gr.Markdown('#### üîó Correlation Analysis')\n",
        "    corr_card = gr.HTML()\n",
        "    corr_plot = gr.Plot()\n",
        "\n",
        "    # Hourly Patterns\n",
        "    gr.Markdown('#### ‚è∞ Hourly Patterns')\n",
        "    hourly_card = gr.HTML()\n",
        "    hourly_plot = gr.Plot()\n",
        "\n",
        "    # Daily Trends\n",
        "    gr.Markdown('#### üìÖ Daily Trends')\n",
        "    daily_card = gr.HTML()\n",
        "    daily_plot = gr.Plot()\n",
        "\n",
        "    # Distribution Analysis\n",
        "    gr.Markdown('#### üìä Distribution Analysis (Histograms)')\n",
        "    dist_card = gr.HTML()\n",
        "    dist_plot = gr.Plot()\n",
        "\n",
        "    # Moving Averages\n",
        "    gr.Markdown('#### üìâ Moving Averages')\n",
        "    with gr.Row():\n",
        "        ma_variable = gr.Dropdown(\n",
        "            choices=['temperature', 'humidity', 'soil'],\n",
        "            value='temperature',\n",
        "            label='Select Variable'\n",
        "        )\n",
        "        ma_btn = gr.Button('Generate Moving Average')\n",
        "    ma_card = gr.HTML()\n",
        "    ma_plot = gr.Plot()\n",
        "\n",
        "    # Wire up refresh button (11 outputs - without scatter)\n",
        "    refresh_btn.click(\n",
        "        dashboard_screen,\n",
        "        outputs=[\n",
        "            kpi_html, stats_html, ts_plot,\n",
        "            corr_card, corr_plot,\n",
        "            hourly_card, hourly_plot,\n",
        "            daily_card, daily_plot,\n",
        "            dist_card, dist_plot\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Wire up moving average\n",
        "    ma_btn.click(\n",
        "        dashboard_moving_avg,\n",
        "        inputs=ma_variable,\n",
        "        outputs=[ma_card, ma_plot]\n",
        "    )\n",
        "\n",
        "\n",
        "def build_search_engine_tab():\n",
        "    build_placeholder_tab(\"üîç Search Engine\")\n",
        "\n",
        "#def build_rag_chat_tab():\n",
        " #   build_placeholder_tab(\"üí¨ RAG Chat\")\n",
        "\n",
        "def build_sync_data_tab():\n",
        "    \"\"\"Sync data from server to Firebase\"\"\"\n",
        "\n",
        "    gr.Markdown('Sync Data from to Server')\n",
        "    gr.Markdown('Upload IoT Data to FireBase')\n",
        "\n",
        "    sync_btn = gr.Button('üîÑ Sync New Data', variant='primary', size='lg')\n",
        "    sync_output = gr.Textbox(label='Status', lines=5)\n",
        "\n",
        "    sync_btn.click(sync_screen, outputs=sync_output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ ◊®◊©◊ô◊û◊™ ◊î◊ò◊ê◊ë◊ô◊ù ‚Äî ◊ñ◊î ◊î◊û◊ß◊ï◊ù ◊î◊ô◊ó◊ô◊ì ◊©◊û◊ï◊°◊ô◊§◊ô◊ù/◊û◊ï◊®◊ô◊ì◊ô◊ù ◊ò◊ê◊ë◊ô◊ù\n",
        "TABS = [\n",
        "    (\"üå± Realtime Dashboard\", build_realtime_dashboard_tab),\n",
        "    (\"üìä IoT Dashboard\", build_iot_dashboard_tab),\n",
        "    (\"üìÑ Generate Report\", build_generate_report_tab),\n",
        "    (\"üñºÔ∏è Plant Disease Detection\", build_plant_disease_detection_tab),\n",
        "    (\"üí¨ RAG Chat\", build_rag_chat_tab),\n",
        "    (\"üîÑ Sync Data\", build_sync_data_tab),\n",
        "]"
      ],
      "metadata": {
        "id": "lFEXSm_SUr4-"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìà Visualization Functions (IoT Dashboard)\n"
      ],
      "metadata": {
        "id": "33OVXQN6PXGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Cell 7: Complete Visualization Functions (WITHOUT SCATTER ANALYSIS)\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import numpy as np\n",
        "\n",
        "# Sensor configuration\n",
        "SENSORS = [\n",
        "    ('temperature', '¬∞C', COLORS['temperature']['color'], COLORS['temperature']['color'], 'TEMPERATURE'),\n",
        "    ('humidity', '%', COLORS['humidity']['color'], COLORS['humidity']['color'], 'HUMIDITY'),\n",
        "    ('soil', '%', COLORS['soil']['color'], COLORS['soil']['color'], 'SOIL MOISTURE')\n",
        "]\n",
        "print('‚úì Sensor config loaded')\n",
        "\n",
        "# ============================================================================\n",
        "# COMPONENT FUNCTIONS\n",
        "# ============================================================================\n",
        "def create_kpi_card(label, value, unit, change, change_label, trend=\"up\", border_color=None):\n",
        "    \"\"\"Create KPI card HTML.\"\"\"\n",
        "    bc = border_color or COLORS['temperature']['color']\n",
        "    icon = \"‚Üë\" if trend == \"up\" else (\"‚Üì\" if trend == \"down\" else \"‚Üí\")\n",
        "    return f'''<div class=\"kpi-card\" style=\"border-left-color: {bc};\">\n",
        "        <p class=\"kpi-label\">{label}</p>\n",
        "        <p class=\"kpi-value\">{value}<span style=\"font-size: 24px;\">{unit}</span></p>\n",
        "        <p class=\"kpi-change trend-{trend}\"><span>{icon}</span><span>{change} {change_label}</span></p>\n",
        "    </div>'''\n",
        "\n",
        "def create_status_badge(text=\"LIVE\", pulse=True):\n",
        "    \"\"\"Create status badge HTML.\"\"\"\n",
        "    pulse_dot = \"<span class='status-dot'></span>\" if pulse else \"\"\n",
        "    return f'<span class=\"status-badge\">{pulse_dot}{text}</span>'\n",
        "\n",
        "def create_explanation_card(title, description, interpretation, gradient=None):\n",
        "    \"\"\"Create explanation card HTML.\"\"\"\n",
        "    grad = gradient or COLORS['temperature']['color']\n",
        "    return f'''<div class=\"explanation-card\" style=\"background: {grad};\">\n",
        "        <h3>üìä {title}</h3><p><strong>What it shows:</strong> {description}</p>\n",
        "        <p><strong>How to interpret:</strong> {interpretation}</p></div>'''\n",
        "\n",
        "print('‚úì Component functions loaded')\n",
        "\n",
        "# ============================================================================\n",
        "# STATISTICS CARDS\n",
        "# ============================================================================\n",
        "def create_stat_cards_html(df):\n",
        "    \"\"\"Create comprehensive statistics cards for all sensors.\"\"\"\n",
        "    if len(df) == 0:\n",
        "        return \"<p>No data available</p>\"\n",
        "\n",
        "    explanations = {\n",
        "        'Mean': 'Average value. Sum √∑ count.',\n",
        "        'Median': 'Middle value. 50% above, 50% below.',\n",
        "        'Std Dev': 'Variability around mean. Low=consistent, High=variable.',\n",
        "        'Min': 'Lowest recorded value.',\n",
        "        'Max': 'Highest recorded value.',\n",
        "        'Q25': '25th percentile. 25% below this.',\n",
        "        'Q75': '75th percentile. 75% below this.',\n",
        "        'IQR': 'Interquartile range (Q75-Q25).'\n",
        "    }\n",
        "\n",
        "    sensor_colors = {\n",
        "        'TEMPERATURE': {'bg': '#fee2e2', 'text': '#991b1b', 'border': '#ef4444'},\n",
        "        'HUMIDITY': {'bg': '#dbeafe', 'text': '#1e40af', 'border': '#3b82f6'},\n",
        "        'SOIL MOISTURE': {'bg': '#e9d5ff', 'text': '#6b21a8', 'border': '#8b5cf6'}\n",
        "    }\n",
        "\n",
        "    html = '<div style=\"display: grid; grid-template-columns: repeat(3, 1fr); gap: 16px; margin: 20px 0;\">'\n",
        "\n",
        "    for var, unit, _, _, name in SENSORS:\n",
        "        stats = {k: round(v, 2) for k, v in {\n",
        "            'Mean': df[var].mean(),\n",
        "            'Median': df[var].median(),\n",
        "            'Std Dev': df[var].std(),\n",
        "            'Min': df[var].min(),\n",
        "            'Max': df[var].max(),\n",
        "            'Q25': df[var].quantile(0.25),\n",
        "            'Q75': df[var].quantile(0.75),\n",
        "            'IQR': df[var].quantile(0.75) - df[var].quantile(0.25)\n",
        "        }.items()}\n",
        "\n",
        "        colors = sensor_colors[name]\n",
        "\n",
        "        html += f'''\n",
        "        <div style=\"\n",
        "            background: {colors['bg']};\n",
        "            border: 3px solid {colors['border']};\n",
        "            border-radius: 12px;\n",
        "            padding: 20px;\n",
        "            box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
        "        \">\n",
        "            <h2 style=\"\n",
        "                color: {colors['text']};\n",
        "                margin: 0 0 16px 0;\n",
        "                font-size: 20px;\n",
        "                font-weight: 700;\n",
        "                text-align: center;\n",
        "            \">{name}</h2>\n",
        "            <div style=\"display: grid; grid-template-columns: repeat(2, 1fr); gap: 12px;\">\n",
        "        '''\n",
        "\n",
        "        for stat_name, stat_val in stats.items():\n",
        "            html += f'''\n",
        "            <div style=\"\n",
        "                background: white;\n",
        "                border-radius: 8px;\n",
        "                padding: 12px;\n",
        "                box-shadow: 0 1px 3px rgba(0,0,0,0.1);\n",
        "            \">\n",
        "                <div style=\"\n",
        "                    display: flex;\n",
        "                    justify-content: space-between;\n",
        "                    align-items: center;\n",
        "                    margin-bottom: 4px;\n",
        "                \">\n",
        "                    <div style=\"\n",
        "                        font-size: 12px;\n",
        "                        font-weight: 600;\n",
        "                        color: {colors['text']};\n",
        "                    \">{stat_name}</div>\n",
        "                    <div class=\"info-icon\" style=\"\n",
        "                        width: 18px;\n",
        "                        height: 18px;\n",
        "                        border-radius: 50%;\n",
        "                        background: {colors['border']};\n",
        "                        color: white;\n",
        "                        display: flex;\n",
        "                        align-items: center;\n",
        "                        justify-content: center;\n",
        "                        font-size: 11px;\n",
        "                        font-weight: 700;\n",
        "                    \">i\n",
        "                        <span class=\"tooltip-text\">{explanations[stat_name]}</span>\n",
        "                    </div>\n",
        "                </div>\n",
        "                <div style=\"\n",
        "                    font-size: 24px;\n",
        "                    font-weight: 700;\n",
        "                    color: {colors['text']};\n",
        "                \">{stat_val}{unit}</div>\n",
        "            </div>\n",
        "            '''\n",
        "\n",
        "        html += '</div></div>'\n",
        "\n",
        "    html += '</div>'\n",
        "    return html\n",
        "\n",
        "print('‚úì Statistics functions loaded')\n",
        "\n",
        "# ============================================================================\n",
        "# CHART STYLING\n",
        "# ============================================================================\n",
        "def apply_chart_styling(fig, title=\"\", xaxis_title=\"\", yaxis_title=\"\", height=400):\n",
        "    \"\"\"Apply consistent styling to all charts.\"\"\"\n",
        "    fig.update_layout(\n",
        "        title=dict(text=title, font=dict(size=20)),\n",
        "        xaxis_title=xaxis_title,\n",
        "        yaxis_title=yaxis_title,\n",
        "        font=dict(family=\"Inter, sans-serif\", size=14),\n",
        "        plot_bgcolor='white',\n",
        "        paper_bgcolor='white',\n",
        "        height=height,\n",
        "        hovermode='x unified'\n",
        "    )\n",
        "    fig.update_xaxes(showgrid=False, title_font=dict(size=14, color='#6b7280'), tickfont=dict(size=12))\n",
        "    fig.update_yaxes(showgrid=True, gridcolor='#E5E7EB', title_font=dict(size=14, color='#6b7280'), tickfont=dict(size=12))\n",
        "    return fig\n",
        "\n",
        "print('‚úì Chart styling loaded')\n",
        "\n",
        "# ============================================================================\n",
        "# PLOT FUNCTIONS\n",
        "# ============================================================================\n",
        "def time_series_overview(df):\n",
        "    \"\"\"Time series for all sensors.\"\"\"\n",
        "    fig = go.Figure()\n",
        "    for col, unit, color, _, _ in SENSORS:\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=df['timestamp'],\n",
        "            y=df[col],\n",
        "            name=col.capitalize(),\n",
        "            mode='lines',\n",
        "            line=dict(color=color, width=2),\n",
        "            hovertemplate=f'%{{y:.1f}}{unit}<extra></extra>'\n",
        "        ))\n",
        "    apply_chart_styling(fig, \"Sensor Data Time Series\", \"Time\", \"Measurement (¬∞C / %)\", 500)\n",
        "    return create_explanation_card(\n",
        "        \"Time Series Overview\",\n",
        "        \"All sensor measurements over time.\",\n",
        "        \"Look for trends, cycles, and sudden changes.\"\n",
        "    ), fig\n",
        "\n",
        "def calculate_correlations(df):\n",
        "    \"\"\"Correlation matrix between sensors.\"\"\"\n",
        "    corr = df[['temperature', 'humidity', 'soil']].corr()\n",
        "    fig = px.imshow(\n",
        "        corr,\n",
        "        labels=dict(color=\"Correlation\"),\n",
        "        x=['Temperature', 'Humidity', 'Soil'],\n",
        "        y=['Temperature', 'Humidity', 'Soil'],\n",
        "        color_continuous_scale='RdBu_r',\n",
        "        zmin=-1,\n",
        "        zmax=1,\n",
        "        aspect=\"auto\"\n",
        "    )\n",
        "    apply_chart_styling(fig, \"Correlation Matrix\", \"Variables\", \"Variables\", 500)\n",
        "\n",
        "    # Add correlation values\n",
        "    for i in range(len(corr)):\n",
        "        for j in range(len(corr)):\n",
        "            fig.add_annotation(\n",
        "                x=j, y=i,\n",
        "                text=str(round(corr.iloc[i, j], 3)),\n",
        "                showarrow=False,\n",
        "                font=dict(size=14, color='black' if abs(corr.iloc[i, j]) < 0.5 else 'white', weight=600)\n",
        "            )\n",
        "\n",
        "    return create_explanation_card(\n",
        "        \"Correlation Analysis\",\n",
        "        \"Linear relationships between sensors. +1=perfect positive, -1=perfect negative, 0=no relationship.\",\n",
        "        \"High correlations indicate sensors respond together.\",\n",
        "        COLORS['humidity']['color']\n",
        "    ), fig\n",
        "\n",
        "def hourly_patterns(df):\n",
        "    \"\"\"Average values by hour of day.\"\"\"\n",
        "    df_copy = df.copy()\n",
        "    df_copy['hour'] = df_copy['timestamp'].dt.hour\n",
        "    hourly = df_copy.groupby('hour')[['temperature', 'humidity', 'soil']].mean()\n",
        "\n",
        "    fig = go.Figure()\n",
        "    for col, _, color, _, _ in SENSORS:\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=hourly.index,\n",
        "            y=hourly[col],\n",
        "            name=col.capitalize(),\n",
        "            mode='lines+markers',\n",
        "            line=dict(color=color, width=2.5),\n",
        "            marker=dict(size=8)\n",
        "        ))\n",
        "\n",
        "    apply_chart_styling(fig, \"Average Values by Hour\", \"Hour (0-23)\", \"Average Measurement (¬∞C / %)\", 450)\n",
        "    return create_explanation_card(\n",
        "        \"Hourly Patterns\",\n",
        "        \"Average values per hour showing daily cycles.\",\n",
        "        \"Look for peaks and valleys that repeat daily.\",\n",
        "        COLORS['soil']['color']\n",
        "    ), fig\n",
        "\n",
        "def daily_patterns(df):\n",
        "    \"\"\"Daily trends with min-max ranges.\"\"\"\n",
        "    df_copy = df.copy()\n",
        "    df_copy['date'] = df_copy['timestamp'].dt.date\n",
        "    daily = df_copy.groupby('date')[['temperature', 'humidity', 'soil']].agg(['mean', 'min', 'max'])\n",
        "\n",
        "    fig = make_subplots(\n",
        "        rows=3, cols=1,\n",
        "        subplot_titles=('Temperature (¬∞C)', 'Humidity (%)', 'Soil (%)'),\n",
        "        vertical_spacing=0.08\n",
        "    )\n",
        "\n",
        "    for idx, (var, _, color, _, _) in enumerate(SENSORS, 1):\n",
        "        dates = [str(d) for d in daily.index]\n",
        "        r, g, b = int(color[1:3], 16), int(color[3:5], 16), int(color[5:7], 16)\n",
        "\n",
        "        # Min-max range\n",
        "        fig.add_trace(go.Scatter(x=dates, y=daily[var]['max'], mode='lines', line=dict(width=0), showlegend=False, hoverinfo='skip'), row=idx, col=1)\n",
        "        fig.add_trace(go.Scatter(x=dates, y=daily[var]['min'], mode='lines', line=dict(width=0),\n",
        "                                fill='tonexty', fillcolor=f\"rgba({r},{g},{b},0.2)\", showlegend=False, hoverinfo='skip'), row=idx, col=1)\n",
        "\n",
        "        # Mean line\n",
        "        fig.add_trace(go.Scatter(x=dates, y=daily[var]['mean'], mode='lines+markers',\n",
        "                                line=dict(color=color, width=2.5), marker=dict(size=6), name='Mean', showlegend=(idx==1)), row=idx, col=1)\n",
        "\n",
        "    fig.update_xaxes(title_text=\"Date\", row=3, col=1)\n",
        "    fig.update_yaxes(title_text=\"Temperature (¬∞C)\", row=1, col=1)\n",
        "    fig.update_yaxes(title_text=\"Humidity (%)\", row=2, col=1)\n",
        "    fig.update_yaxes(title_text=\"Soil Moisture (%)\", row=3, col=1)\n",
        "    fig.update_layout(height=900)\n",
        "\n",
        "    return create_explanation_card(\n",
        "        \"Daily Trends\",\n",
        "        \"Daily means with min-max ranges (shaded).\",\n",
        "        \"Wider shading = more variability. Look for trends and unusual days.\"\n",
        "    ), fig\n",
        "\n",
        "def distribution_analysis(df):\n",
        "    \"\"\"Histograms showing distribution of sensor values.\"\"\"\n",
        "    fig = make_subplots(\n",
        "        rows=1, cols=3,\n",
        "        subplot_titles=('Temperature (¬∞C)', 'Humidity (%)', 'Soil Moisture (%)')\n",
        "    )\n",
        "\n",
        "    # Temperature histogram\n",
        "    temp_data = df['temperature'].values\n",
        "    temp_min, temp_max = temp_data.min(), temp_data.max()\n",
        "    temp_padding = (temp_max - temp_min) * 0.1\n",
        "    temp_bins = np.linspace(temp_min - temp_padding, temp_max + temp_padding, 31)\n",
        "    temp_counts, temp_edges = np.histogram(temp_data, bins=temp_bins)\n",
        "    temp_centers = (temp_edges[:-1] + temp_edges[1:]) / 2\n",
        "\n",
        "    fig.add_trace(go.Bar(\n",
        "        x=temp_centers,\n",
        "        y=temp_counts,\n",
        "        name='Temperature',\n",
        "        marker_color=COLORS['temperature']['color'],\n",
        "        width=(temp_max - temp_min) / 30 * 0.9,\n",
        "        hovertemplate='%{x:.1f}¬∞C: %{y} readings<extra></extra>'\n",
        "    ), row=1, col=1)\n",
        "\n",
        "    # Humidity histogram\n",
        "    humidity_data = df['humidity'].values\n",
        "    humidity_min, humidity_max = humidity_data.min(), humidity_data.max()\n",
        "    humidity_padding = (humidity_max - humidity_min) * 0.1\n",
        "    humidity_bins = np.linspace(humidity_min - humidity_padding, humidity_max + humidity_padding, 31)\n",
        "    humidity_counts, humidity_edges = np.histogram(humidity_data, bins=humidity_bins)\n",
        "    humidity_centers = (humidity_edges[:-1] + humidity_edges[1:]) / 2\n",
        "\n",
        "    fig.add_trace(go.Bar(\n",
        "        x=humidity_centers,\n",
        "        y=humidity_counts,\n",
        "        name='Humidity',\n",
        "        marker_color=COLORS['humidity']['color'],\n",
        "        width=(humidity_max - humidity_min) / 30 * 0.9,\n",
        "        hovertemplate='%{x:.1f}%: %{y} readings<extra></extra>'\n",
        "    ), row=1, col=2)\n",
        "\n",
        "    # Soil histogram\n",
        "    soil_data = df['soil'].values\n",
        "    soil_min, soil_max = soil_data.min(), soil_data.max()\n",
        "    soil_padding = (soil_max - soil_min) * 0.1\n",
        "    soil_bins = np.linspace(soil_min - soil_padding, soil_max + soil_padding, 31)\n",
        "    soil_counts, soil_edges = np.histogram(soil_data, bins=soil_bins)\n",
        "    soil_centers = (soil_edges[:-1] + soil_edges[1:]) / 2\n",
        "\n",
        "    fig.add_trace(go.Bar(\n",
        "        x=soil_centers,\n",
        "        y=soil_counts,\n",
        "        name='Soil Moisture',\n",
        "        marker_color=COLORS['soil']['color'],\n",
        "        width=(soil_max - soil_min) / 30 * 0.9,\n",
        "        hovertemplate='%{x:.1f}%: %{y} readings<extra></extra>'\n",
        "    ), row=1, col=3)\n",
        "\n",
        "    # Configure axes\n",
        "    fig.update_xaxes(title_text=\"Temperature (¬∞C)\", row=1, col=1)\n",
        "    fig.update_xaxes(title_text=\"Humidity (%)\", row=1, col=2)\n",
        "    fig.update_xaxes(title_text=\"Soil Moisture (%)\", row=1, col=3)\n",
        "    fig.update_yaxes(title_text=\"Number of Readings\", row=1, col=1)\n",
        "    fig.update_yaxes(title_text=\"Number of Readings\", row=1, col=2)\n",
        "    fig.update_yaxes(title_text=\"Number of Readings\", row=1, col=3)\n",
        "\n",
        "    fig.update_layout(height=400, showlegend=False, plot_bgcolor='white', paper_bgcolor='white')\n",
        "\n",
        "    return create_explanation_card(\n",
        "        \"Distribution Analysis\",\n",
        "        \"Frequency of sensor values. Tall bars = common values, short bars = rare values.\",\n",
        "        \"Look for the shape: bell curve = normal, multiple peaks = different patterns.\",\n",
        "        COLORS['humidity']['color']\n",
        "    ), fig\n",
        "\n",
        "def time_series_decomposition(df, variable='temperature'):\n",
        "    \"\"\"Moving averages showing smoothed trends.\"\"\"\n",
        "    df_s = df.sort_values('timestamp').copy()\n",
        "\n",
        "    # Calculate moving averages with different windows\n",
        "    for window in [3, 10, 30]:\n",
        "        df_s[f'MA_{window}'] = df_s[variable].rolling(window, center=True).mean()\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Raw data\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=df_s['timestamp'],\n",
        "        y=df_s[variable],\n",
        "        name='Raw',\n",
        "        mode='lines',\n",
        "        line=dict(width=1, color='#4B5563'),\n",
        "        opacity=0.6\n",
        "    ))\n",
        "\n",
        "    # Moving averages\n",
        "    for ma, color, width in [('MA_3', '#10b981', 1.5), ('MA_10', '#3b82f6', 2.5), ('MA_30', '#ef4444', 3.5)]:\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=df_s['timestamp'],\n",
        "            y=df_s[ma],\n",
        "            name=ma,\n",
        "            line=dict(width=width, color=color)\n",
        "        ))\n",
        "\n",
        "    unit = '¬∞C' if variable == 'temperature' else '%'\n",
        "    apply_chart_styling(fig, f'Moving Averages - {variable.capitalize()}', 'Time', f'{variable.capitalize()} ({unit})', 450)\n",
        "\n",
        "    return create_explanation_card(\n",
        "        \"Moving Averages\",\n",
        "        \"Smoothed trends at different scales (3, 10, 30 measurements).\",\n",
        "        \"Thicker lines=longer windows=smoother trends.\"\n",
        "    ), fig\n",
        "\n",
        "# ============================================================================\n",
        "# DASHBOARD FUNCTIONS FOR GRADIO\n",
        "# ============================================================================\n",
        "\n",
        "def create_kpi_cards(df):\n",
        "    \"\"\"Create simple KPI cards for dashboard.\"\"\"\n",
        "    if df.empty:\n",
        "        return \"<div style='padding: 20px; text-align: center;'>◊ê◊ô◊ü ◊†◊™◊ï◊†◊ô◊ù ◊ñ◊û◊ô◊†◊ô◊ù</div>\"\n",
        "\n",
        "    latest = df.iloc[-1]\n",
        "\n",
        "    # Calculate trends\n",
        "    if len(df) > 10:\n",
        "        prev = df.iloc[-10]\n",
        "        temp_trend = \"up\" if latest['temperature'] > prev['temperature'] else \"down\" if latest['temperature'] < prev['temperature'] else \"stable\"\n",
        "        hum_trend = \"up\" if latest['humidity'] > prev['humidity'] else \"down\" if latest['humidity'] < prev['humidity'] else \"stable\"\n",
        "        soil_trend = \"up\" if latest['soil'] > prev['soil'] else \"down\" if latest['soil'] < prev['soil'] else \"stable\"\n",
        "\n",
        "        temp_change = f\"{abs(latest['temperature'] - prev['temperature']):.1f}\"\n",
        "        hum_change = f\"{abs(latest['humidity'] - prev['humidity']):.1f}\"\n",
        "        soil_change = f\"{abs(latest['soil'] - prev['soil']):.1f}\"\n",
        "    else:\n",
        "        temp_trend = hum_trend = soil_trend = \"stable\"\n",
        "        temp_change = hum_change = soil_change = \"0.0\"\n",
        "\n",
        "    # Create HTML\n",
        "    html = f\"\"\"\n",
        "    <div style=\"display: grid; grid-template-columns: repeat(3, 1fr); gap: 24px; margin: 20px 0;\">\n",
        "        {create_kpi_card('üå°Ô∏è Temperature', f'{latest[\"temperature\"]:.1f}', '¬∞C', temp_change, 'from last 10', temp_trend, COLORS['temperature']['color'])}\n",
        "        {create_kpi_card('üíß Humidity', f'{latest[\"humidity\"]:.1f}', '%', hum_change, 'from last 10', hum_trend, COLORS['humidity']['color'])}\n",
        "        {create_kpi_card('üå± Soil Moisture', f'{latest[\"soil\"]:.1f}', '%', soil_change, 'from last 10', soil_trend, COLORS['soil']['color'])}\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    return html\n",
        "\n",
        "def create_time_series_plot(df):\n",
        "    \"\"\"Create time series plot for dashboard.\"\"\"\n",
        "    if df.empty:\n",
        "        fig = go.Figure()\n",
        "        fig.add_annotation(\n",
        "            text=\"No data available\",\n",
        "            xref=\"paper\", yref=\"paper\",\n",
        "            x=0.5, y=0.5, showarrow=False,\n",
        "            font=dict(size=20)\n",
        "        )\n",
        "        fig.update_layout(height=500)\n",
        "        return fig\n",
        "\n",
        "    fig = make_subplots(\n",
        "        rows=3, cols=1,\n",
        "        subplot_titles=('üå°Ô∏è Temperature (¬∞C)', 'üíß Humidity (%)', 'üå± Soil Moisture (%)'),\n",
        "        vertical_spacing=0.08\n",
        "    )\n",
        "\n",
        "    # Temperature\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=df['timestamp'],\n",
        "            y=df['temperature'],\n",
        "            name='Temperature',\n",
        "            line=dict(color=COLORS['temperature']['color'], width=2),\n",
        "            fill='tozeroy',\n",
        "            fillcolor=f\"rgba(239, 68, 68, 0.1)\"\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # Humidity\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=df['timestamp'],\n",
        "            y=df['humidity'],\n",
        "            name='Humidity',\n",
        "            line=dict(color=COLORS['humidity']['color'], width=2),\n",
        "            fill='tozeroy',\n",
        "            fillcolor=f\"rgba(59, 130, 246, 0.1)\"\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "    # Soil\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=df['timestamp'],\n",
        "            y=df['soil'],\n",
        "            name='Soil',\n",
        "            line=dict(color=COLORS['soil']['color'], width=2),\n",
        "            fill='tozeroy',\n",
        "            fillcolor=f\"rgba(139, 92, 246, 0.1)\"\n",
        "        ),\n",
        "        row=3, col=1\n",
        "    )\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_xaxes(showgrid=True, gridcolor='#E5E7EB')\n",
        "    fig.update_yaxes(showgrid=True, gridcolor='#E5E7EB')\n",
        "\n",
        "    fig.update_layout(\n",
        "        height=800,\n",
        "        showlegend=False,\n",
        "        plot_bgcolor='white',\n",
        "        paper_bgcolor='white',\n",
        "        font=dict(family=\"Inter, sans-serif\")\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "print('‚úÖ ALL visualization functions loaded!')\n",
        "print('   ‚úì Time Series')\n",
        "print('   ‚úì Correlations')\n",
        "print('   ‚úì Hourly/Daily Patterns')\n",
        "print('   ‚úì Histograms (Distributions)')\n",
        "print('   ‚úì Moving Averages')\n",
        "print('   ‚úì Statistics Cards')\n",
        "print('   ‚úì Dashboard functions')\n",
        "print('   ‚ùå Scatter Plots (REMOVED)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHqZANXcPWCB",
        "outputId": "38ee1b0e-c3b1-497a-dd2c-f579266a7d80"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Sensor config loaded\n",
            "‚úì Component functions loaded\n",
            "‚úì Statistics functions loaded\n",
            "‚úì Chart styling loaded\n",
            "‚úÖ ALL visualization functions loaded!\n",
            "   ‚úì Time Series\n",
            "   ‚úì Correlations\n",
            "   ‚úì Hourly/Daily Patterns\n",
            "   ‚úì Histograms (Distributions)\n",
            "   ‚úì Moving Averages\n",
            "   ‚úì Statistics Cards\n",
            "   ‚úì Dashboard functions\n",
            "   ‚ùå Scatter Plots (REMOVED)\n",
            "‚úì Sensor config loaded\n",
            "‚úì Component functions loaded\n",
            "‚úì Statistics functions loaded\n",
            "‚úì Chart styling loaded\n",
            "‚úÖ ALL visualization functions loaded!\n",
            "   ‚úì Time Series\n",
            "   ‚úì Correlations\n",
            "   ‚úì Hourly/Daily Patterns\n",
            "   ‚úì Histograms (Distributions)\n",
            "   ‚úì Moving Averages\n",
            "   ‚úì Statistics Cards\n",
            "   ‚úì Dashboard functions\n",
            "   ‚ùå Scatter Plots (REMOVED)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üñ•Ô∏è Screen Functions (IoT Dashboard & Sync)"
      ],
      "metadata": {
        "id": "8M68MbKKPgOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Cell 8: Screen Functions (WITHOUT SCATTER ANALYSIS)\n",
        "\n",
        "def sync_screen():\n",
        "    \"\"\"Sync data screen.\"\"\"\n",
        "    msg, count = sync_new_data_from_server()\n",
        "    return msg\n",
        "\n",
        "def dashboard_screen():\n",
        "    \"\"\"Load all data and return comprehensive dashboard (WITHOUT SCATTER).\"\"\"\n",
        "    df = load_data_from_firebase()\n",
        "\n",
        "    if df.empty:\n",
        "        empty_msg = \"<div style='padding: 20px; text-align: center;'>◊ê◊ô◊ü ◊†◊™◊ï◊†◊ô◊ù. ◊ú◊ó◊• ◊¢◊ú Sync Data!</div>\"\n",
        "        return empty_msg, None, None, None, None, None, None, None, None, None, None\n",
        "\n",
        "    # Generate all visualizations (WITHOUT SCATTER)\n",
        "    kpi = create_kpi_cards(df)\n",
        "    stats = create_stat_cards_html(df)\n",
        "    ts = create_time_series_plot(df)\n",
        "    corr_card, corr_plot = calculate_correlations(df)\n",
        "    hourly_card, hourly_plot = hourly_patterns(df)\n",
        "    daily_card, daily_plot = daily_patterns(df)\n",
        "    dist_card, dist_plot = distribution_analysis(df)\n",
        "\n",
        "    return kpi, stats, ts, corr_card, corr_plot, hourly_card, hourly_plot, daily_card, daily_plot, dist_card, dist_plot\n",
        "\n",
        "def dashboard_moving_avg(variable):\n",
        "    \"\"\"Generate moving average plot for selected variable.\"\"\"\n",
        "    df = load_data_from_firebase()\n",
        "    if df.empty:\n",
        "        return None, \"◊ê◊ô◊ü ◊†◊™◊ï◊†◊ô◊ù\"\n",
        "    ma_card, ma_plot = time_series_decomposition(df, variable)\n",
        "    return ma_card, ma_plot\n",
        "\n",
        "print('‚úÖ All screen functions loaded!')\n",
        "print('   üìä Dashboard (without scatter)')\n",
        "print('   üìâ Moving Averages')\n",
        "print('   üîÑ Data Sync')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VlalUqePjB2",
        "outputId": "5bbd78b1-8c71-467a-b8e5-b851dad35fa2"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All screen functions loaded!\n",
            "   üìä Dashboard (without scatter)\n",
            "   üìâ Moving Averages\n",
            "   üîÑ Data Sync\n",
            "‚úÖ All screen functions loaded!\n",
            "   üìä Dashboard (without scatter)\n",
            "   üìâ Moving Averages\n",
            "   üîÑ Data Sync\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ APP BUILDER"
      ],
      "metadata": {
        "id": "RcqPbzgaOxyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_app() -> gr.Blocks:\n",
        "    with gr.Blocks(title=APP_TITLE, css=CUSTOM_CSS) as demo:\n",
        "        # Header\n",
        "        gr.Markdown(\n",
        "            f\"<h1 style='text-align:left;font-size:30px;font-weight:700;margin:0;'>{APP_TITLE}</h1>\"\n",
        "        )\n",
        "        gr.Markdown(\n",
        "            f\"<h1 style='text-align:left;font-size:20px;font-weight:700;margin:0;'>{APP_SUBTITLE}</h1>\"\n",
        "        )\n",
        "\n",
        "        # Tabs\n",
        "        with gr.Tabs():\n",
        "            for tab_name, tab_builder in TABS:\n",
        "                with gr.Tab(tab_name):\n",
        "                    tab_builder()\n",
        "\n",
        "    return demo"
      ],
      "metadata": {
        "id": "pXglJeFNO2rU"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ LAUNCH (ONLY ONE)"
      ],
      "metadata": {
        "id": "rtxmPPB0O17q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    app = build_app()\n",
        "    app.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "Bg5JT_i5O7mq",
        "outputId": "c30d16bc-b192-4f21-ee46-5400a6f3f7f7"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b7d0fc84a45ea71db7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b7d0fc84a45ea71db7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GET indexes/public_index status: 200 | resp: {\"0\":[0,1,2,3,4],\"00\":[2],\"000\":[0,4],\"1\":[0,1,2,3,4],\"01\":[0,1,2,3],\"0001\":[2,3,4],\"2\":[0,1,2,3,4],\"02\":[0],\"002\":[1],\"3\":[0,1,2,3,4],\"03\":[1],\"003\":[1],\"4\":[0,1,2,3,4],\"04\":[2],\"004\":[1],\"5\":[0,1,2,\n",
            "GET indexes/doc_map status: 200 | resp: [\"https://doi.org/10.1038/s41598-025-20629-y\",\"https://doi.org/10.3389/fpls.2016.01419\",\"https://doi.org/10.1038/s41598-025-05102-0\",\"https://doi.org/10.1038/s41598-025-04758-y\",\"https://doi.org/10.21\n",
            "Loaded: terms= 3548 | docs= 5\n",
            "GET indexes/doc_text/0 status: 200 | resp: \"TITLE: Medicinal plant leaf disease classification using optimal weighted features with dilated adaptive DenseNet and attention mechanism | Scientific Reports\\nDESCRIPTION: The agriculture sector pla\n",
            "GET indexes/doc_text/1 status: 200 | resp: \"TITLE: Frontiers | Using Deep Learning for Image-Based Plant Disease Detection\\nDESCRIPTION: Crop diseases are a major threat to food security, but their rapid identification remains difficult in man\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (914 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GET indexes/doc_text/2 status: 200 | resp: \"TITLE: Plant leaf disease detection using vision transformers for precision agriculture | Scientific Reports\\nDESCRIPTION: Plant diseases cause major crop losses worldwide, making early detection ess\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://b7d0fc84a45ea71db7.gradio.live\n"
          ]
        }
      ]
    }
  ]
}