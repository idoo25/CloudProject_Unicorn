{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udf31 CloudGarden - Smart Plant Disease Detection System",
        "## Refactored Version",
        "",
        "**Changes from original:**",
        "- All imports consolidated",
        "- Configuration centralized  ",
        "- Code duplication removed",
        "- Better error handling",
        "- Cleaner organization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udce6 1. Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install all required packages\n",
        "!pip install -q --upgrade gradio pandas matplotlib python-docx plotly\n",
        "!pip install -q --upgrade firebase-admin gdown transformers torch\n",
        "!pip install -q --upgrade beautifulsoup4 lxml nltk requests numpy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcda 2. Imports (Consolidated)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# ALL IMPORTS - SINGLE LOCATION\n",
        "# =============================================================================\n",
        "\n",
        "# Standard library\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import tempfile\n",
        "import warnings\n",
        "from datetime import datetime, timedelta, timezone\n",
        "from collections import defaultdict\n",
        "from typing import Dict, List, Optional, Tuple, Any\n",
        "from urllib.parse import quote\n",
        "\n",
        "# Data processing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Web & HTTP\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Firebase\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, db\n",
        "import gdown\n",
        "\n",
        "# NLP\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# ML\n",
        "from transformers import pipeline\n",
        "\n",
        "# Document generation\n",
        "from docx import Document\n",
        "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
        "from zoneinfo import ZoneInfo\n",
        "\n",
        "# UI\n",
        "import gradio as gr\n",
        "\n",
        "# Initialize NLP tools\n",
        "nltk.download(\"stopwords\", quiet=True)\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"\u2705 All imports loaded successfully\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u2699\ufe0f 3. Configuration (Centralized)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# ALL CONFIGURATION - SINGLE LOCATION\n",
        "# =============================================================================\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Firebase Configuration\n",
        "# -----------------------------------------------------------------------------\n",
        "FIREBASE_KEY_ID = '1ESnh8BIbGKrVEijA9nKNgNJNdD5kAaYC'\n",
        "FIREBASE_KEY_FILE = 'firebase_key.json'\n",
        "FIREBASE_URL = \"https://cloud-81451-default-rtdb.europe-west1.firebasedatabase.app/\"\n",
        "FIREBASE_DB_URL = FIREBASE_URL  # Alias for clarity\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# External Server Configuration\n",
        "# -----------------------------------------------------------------------------\n",
        "BASE_URL = \"https://server-cloud-v645.onrender.com/\"\n",
        "DEFAULT_FEED = \"json\"\n",
        "BATCH_LIMIT = 200\n",
        "REQUEST_TIMEOUT = 30\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Sensor Configuration (NO MORE MAGIC NUMBERS!)\n",
        "# -----------------------------------------------------------------------------\n",
        "SENSOR_VALIDATION_RANGES = {\n",
        "    'temperature': {'min': -50, 'max': 100, 'unit': '\u00b0C'},\n",
        "    'humidity': {'min': 0, 'max': 100, 'unit': '%'},\n",
        "    'soil': {'min': 0, 'max': 100, 'unit': '%'}\n",
        "}\n",
        "\n",
        "PLANT_OPTIMAL_RANGES = {\n",
        "    'temperature': {'min': 18, 'max': 32, 'margin': 1, 'unit': '\u00b0C'},\n",
        "    'humidity': {'min': 35, 'max': 75, 'margin': 3, 'unit': '%'},\n",
        "    'soil': {'min': 20, 'max': 60, 'margin': 3, 'unit': '%'}\n",
        "}\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# ML Model Configuration\n",
        "# -----------------------------------------------------------------------------\n",
        "PLANT_DISEASE_MODEL = \"linkanjarad/mobilenet_v2_1.0_224-plant-disease-identification\"\n",
        "RAG_MODEL_PRIMARY = \"google/flan-t5-small\"\n",
        "RAG_MODEL_FALLBACK = \"google/flan-t5-base\"\n",
        "RAG_MAX_NEW_TOKENS = 160\n",
        "RAG_SNIPPET_CHARS = 300\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# UI Configuration\n",
        "# -----------------------------------------------------------------------------\n",
        "APP_TITLE = \"\ud83c\udf31 CloudGarden\"\n",
        "APP_SUBTITLE = \"Smart Plant Disease Detection System\"\n",
        "\n",
        "# Colors\n",
        "COLORS = {\n",
        "    'temperature': '#ef4444',  # Red\n",
        "    'humidity': '#3b82f6',     # Blue\n",
        "    'soil': '#8b5cf6',         # Purple\n",
        "    'status_ok': '#2ca02c',    # Green\n",
        "    'status_warn': '#ffbf00',  # Yellow\n",
        "    'status_bad': '#d62728'    # Red\n",
        "}\n",
        "\n",
        "# For backward compatibility\n",
        "COLOR_TEMP = COLORS['temperature']\n",
        "COLOR_HUM = COLORS['humidity']\n",
        "COLOR_SOIL = COLORS['soil']\n",
        "STATUS_OK_COLOR = COLORS['status_ok']\n",
        "STATUS_WARN_COLOR = COLORS['status_warn']\n",
        "STATUS_BAD_COLOR = COLORS['status_bad']\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Document URLs for RAG\n",
        "# -----------------------------------------------------------------------------\n",
        "DOC_URLS = [\n",
        "    \"https://doi.org/10.1038/s41598-025-20629-y\",\n",
        "    \"https://doi.org/10.3389/fpls.2016.01419\",\n",
        "    \"https://doi.org/10.1038/s41598-025-05102-0\",\n",
        "    \"https://doi.org/10.1038/s41598-025-04758-y\",\n",
        "    \"https://doi.org/10.2174/0118743315321139240627092707\",\n",
        "]\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# HTTP Configuration\n",
        "# -----------------------------------------------------------------------------\n",
        "BROWSER_HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "}\n",
        "\n",
        "print(\"\u2705 Configuration loaded\")\n",
        "print(f\"   Firebase URL: {FIREBASE_URL[:50]}...\")\n",
        "print(f\"   Server URL: {BASE_URL}\")\n",
        "print(f\"   Batch Limit: {BATCH_LIMIT}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udee0\ufe0f 4. Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# UTILITY FUNCTIONS - Reusable helpers\n",
        "# =============================================================================\n",
        "\n",
        "def validate_sensor_value(value: float, sensor_type: str) -> float:\n",
        "    \"\"\"Validate and clip sensor value to valid range.\"\"\"\n",
        "    ranges = SENSOR_VALIDATION_RANGES.get(sensor_type, {'min': 0, 'max': 100})\n",
        "    return max(ranges['min'], min(ranges['max'], float(value)))\n",
        "\n",
        "\n",
        "def check_optimal_range(value: float, sensor_type: str) -> Tuple[bool, bool, str]:\n",
        "    \"\"\"\n",
        "    Check if value is in optimal range.\n",
        "    Returns: (is_ok, is_warning, message)\n",
        "    \"\"\"\n",
        "    config = PLANT_OPTIMAL_RANGES.get(sensor_type)\n",
        "    if not config:\n",
        "        return True, False, \"Unknown sensor type\"\n",
        "    \n",
        "    min_val, max_val = config['min'], config['max']\n",
        "    margin = config.get('margin', 0)\n",
        "    unit = config.get('unit', '')\n",
        "    \n",
        "    if not (min_val <= value <= max_val):\n",
        "        return False, False, f\"{sensor_type.title()} out of range ({value:.1f}{unit})\"\n",
        "    elif value <= min_val + margin or value >= max_val - margin:\n",
        "        return True, True, f\"{sensor_type.title()} near limit ({value:.1f}{unit})\"\n",
        "    else:\n",
        "        return True, False, f\"{sensor_type.title()} OK ({value:.1f}{unit})\"\n",
        "\n",
        "\n",
        "def parse_timestamp(ts_value, source: str = \"unknown\") -> Optional[pd.Timestamp]:\n",
        "    \"\"\"Universal timestamp parser - handles all formats.\"\"\"\n",
        "    if ts_value is None:\n",
        "        return None\n",
        "    \n",
        "    try:\n",
        "        # Already a timestamp\n",
        "        if isinstance(ts_value, pd.Timestamp):\n",
        "            return ts_value\n",
        "        \n",
        "        # String timestamp\n",
        "        if isinstance(ts_value, str):\n",
        "            return pd.to_datetime(ts_value, errors='coerce', utc=True)\n",
        "        \n",
        "        # Numeric timestamp (unix)\n",
        "        if isinstance(ts_value, (int, float)):\n",
        "            # Detect milliseconds vs seconds\n",
        "            if ts_value > 1e12:  # Milliseconds\n",
        "                return pd.to_datetime(ts_value, unit='ms', utc=True)\n",
        "            else:  # Seconds\n",
        "                return pd.to_datetime(ts_value, unit='s', utc=True)\n",
        "        \n",
        "        return pd.to_datetime(ts_value, errors='coerce', utc=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Failed to parse timestamp from {source}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def safe_float(value, default: float = 0.0) -> float:\n",
        "    \"\"\"Safely convert to float.\"\"\"\n",
        "    try:\n",
        "        return float(value)\n",
        "    except (ValueError, TypeError):\n",
        "        return default\n",
        "\n",
        "\n",
        "def format_timestamp_key(ts_string: str) -> str:\n",
        "    \"\"\"Convert timestamp to Firebase-safe key.\"\"\"\n",
        "    return ts_string.replace(':', '-').replace('.', '-')\n",
        "\n",
        "\n",
        "def normalize_series(series: pd.Series) -> pd.Series:\n",
        "    \"\"\"Normalize a series to 0-1 range.\"\"\"\n",
        "    mn, mx = float(series.min()), float(series.max())\n",
        "    if mx - mn == 0:\n",
        "        return series * 0.0\n",
        "    return (series - mn) / (mx - mn)\n",
        "\n",
        "\n",
        "print(\"\u2705 Utility functions loaded\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd25 5. Firebase Service"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# FIREBASE SERVICE - All Firebase operations in one place\n",
        "# =============================================================================\n",
        "\n",
        "class FirebaseService:\n",
        "    \"\"\"Centralized Firebase operations.\"\"\"\n",
        "    \n",
        "    _initialized = False\n",
        "    _http_session = requests.Session()\n",
        "    \n",
        "    @classmethod\n",
        "    def initialize(cls) -> bool:\n",
        "        \"\"\"Initialize Firebase connection.\"\"\"\n",
        "        if cls._initialized:\n",
        "            return True\n",
        "        \n",
        "        # Download credentials if needed\n",
        "        if os.path.exists(FIREBASE_KEY_FILE):\n",
        "            os.remove(FIREBASE_KEY_FILE)\n",
        "        \n",
        "        print('\ud83d\udce5 Downloading Firebase credentials...')\n",
        "        try:\n",
        "            url = f'https://drive.google.com/uc?id={FIREBASE_KEY_ID}'\n",
        "            gdown.download(url, FIREBASE_KEY_FILE, quiet=True, fuzzy=True)\n",
        "            \n",
        "            with open(FIREBASE_KEY_FILE, 'r') as f:\n",
        "                creds = json.load(f)\n",
        "            print(f'\u2713 Project: {creds.get(\"project_id\")}')\n",
        "        except Exception as e:\n",
        "            print(f'\u26a0\ufe0f Auto-download failed: {e}')\n",
        "            print('Please upload firebase_key.json manually')\n",
        "            return False\n",
        "        \n",
        "        # Initialize Firebase Admin SDK\n",
        "        if not firebase_admin._apps:\n",
        "            firebase_admin.initialize_app(\n",
        "                credentials.Certificate(FIREBASE_KEY_FILE),\n",
        "                {'databaseURL': FIREBASE_DB_URL}\n",
        "            )\n",
        "        \n",
        "        cls._initialized = True\n",
        "        print('\u2705 Firebase initialized')\n",
        "        return True\n",
        "    \n",
        "    @classmethod\n",
        "    def get_reference(cls, path: str = '/'):\n",
        "        \"\"\"Get Firebase database reference.\"\"\"\n",
        "        if not cls._initialized:\n",
        "            cls.initialize()\n",
        "        return db.reference(path)\n",
        "    \n",
        "    @classmethod\n",
        "    def http_get(cls, path: str) -> Optional[Any]:\n",
        "        \"\"\"HTTP GET from Firebase REST API.\"\"\"\n",
        "        url = f\"{FIREBASE_URL.rstrip('/')}/{path}.json\"\n",
        "        try:\n",
        "            resp = cls._http_session.get(url, timeout=REQUEST_TIMEOUT)\n",
        "            if resp.status_code == 200:\n",
        "                return resp.json()\n",
        "            print(f\"Firebase GET {path} failed: {resp.status_code}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Firebase GET error: {e}\")\n",
        "        return None\n",
        "    \n",
        "    @classmethod\n",
        "    def http_put(cls, path: str, data: Any) -> bool:\n",
        "        \"\"\"HTTP PUT to Firebase REST API.\"\"\"\n",
        "        url = f\"{FIREBASE_URL.rstrip('/')}/{path}.json\"\n",
        "        try:\n",
        "            resp = cls._http_session.put(url, json=data, timeout=REQUEST_TIMEOUT)\n",
        "            return resp.status_code == 200\n",
        "        except Exception as e:\n",
        "            print(f\"Firebase PUT error: {e}\")\n",
        "        return False\n",
        "    \n",
        "    @classmethod\n",
        "    def get_sensor_data(cls) -> pd.DataFrame:\n",
        "        \"\"\"Load all sensor data from Firebase.\"\"\"\n",
        "        try:\n",
        "            data = cls.get_reference('/sensor_data').get()\n",
        "            if not data:\n",
        "                return pd.DataFrame()\n",
        "            \n",
        "            records = []\n",
        "            for v in data.values():\n",
        "                records.append({\n",
        "                    'timestamp': parse_timestamp(v.get('created_at'), 'firebase'),\n",
        "                    'temperature': validate_sensor_value(v.get('temperature', 0), 'temperature'),\n",
        "                    'humidity': validate_sensor_value(v.get('humidity', 0), 'humidity'),\n",
        "                    'soil': validate_sensor_value(v.get('soil', 0), 'soil')\n",
        "                })\n",
        "            \n",
        "            df = pd.DataFrame(records)\n",
        "            df = df.dropna(subset=['timestamp'])\n",
        "            df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading sensor data: {e}\")\n",
        "            return pd.DataFrame()\n",
        "    \n",
        "    @classmethod\n",
        "    def save_sensor_reading(cls, data: Dict) -> bool:\n",
        "        \"\"\"Save a single sensor reading.\"\"\"\n",
        "        try:\n",
        "            timestamp_key = format_timestamp_key(data['created_at'])\n",
        "            \n",
        "            record = {\n",
        "                'created_at': data['created_at'],\n",
        "                'temperature': validate_sensor_value(data.get('temperature', 0), 'temperature'),\n",
        "                'humidity': validate_sensor_value(data.get('humidity', 0), 'humidity'),\n",
        "                'soil': validate_sensor_value(data.get('soil', 0), 'soil')\n",
        "            }\n",
        "            \n",
        "            cls.get_reference(f'/sensor_data/{timestamp_key}').set(record)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving sensor data: {e}\")\n",
        "            return False\n",
        "    \n",
        "    @classmethod\n",
        "    def get_latest_timestamp(cls) -> Optional[str]:\n",
        "        \"\"\"Get the most recent timestamp from Firebase.\"\"\"\n",
        "        try:\n",
        "            ref = cls.get_reference('/sensor_data')\n",
        "            latest = ref.order_by_child('created_at').limit_to_last(1).get()\n",
        "            if latest:\n",
        "                return list(latest.values())[0]['created_at']\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting latest timestamp: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Initialize on load\n",
        "FirebaseService.initialize()\n",
        "\n",
        "# Backward-compatible functions\n",
        "def load_data_from_firebase():\n",
        "    \"\"\"Backward compatible function.\"\"\"\n",
        "    return FirebaseService.get_sensor_data()\n",
        "\n",
        "def firebase_get(path):\n",
        "    \"\"\"Backward compatible function.\"\"\"\n",
        "    return FirebaseService.http_get(path)\n",
        "\n",
        "def save_to_firebase(data, path):\n",
        "    \"\"\"Backward compatible function.\"\"\"\n",
        "    return FirebaseService.http_put(path, data)\n",
        "\n",
        "print(\"\u2705 Firebase Service ready\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca 6. Data Service"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# DATA SERVICE - Unified data loading and sync\n",
        "# =============================================================================\n",
        "\n",
        "class DataService:\n",
        "    \"\"\"Unified data access layer.\"\"\"\n",
        "    \n",
        "    _http_session = requests.Session()\n",
        "    \n",
        "    @classmethod\n",
        "    def fetch_from_server(cls, feed: str = DEFAULT_FEED, limit: int = BATCH_LIMIT, \n",
        "                          before_timestamp: str = None) -> Optional[Dict]:\n",
        "        \"\"\"Fetch data from external IoT server.\"\"\"\n",
        "        params = {\"feed\": feed, \"limit\": limit}\n",
        "        if before_timestamp:\n",
        "            params[\"before_created_at\"] = before_timestamp\n",
        "        \n",
        "        try:\n",
        "            resp = cls._http_session.get(\n",
        "                f\"{BASE_URL}/history\",\n",
        "                params=params,\n",
        "                timeout=REQUEST_TIMEOUT * 6  # Longer timeout for history\n",
        "            )\n",
        "            return resp.json()\n",
        "        except Exception as e:\n",
        "            print(f\"Server fetch error: {e}\")\n",
        "            return None\n",
        "    \n",
        "    @classmethod\n",
        "    def load_iot_data(cls, feed: str = DEFAULT_FEED, limit: int = 50) -> Optional[pd.DataFrame]:\n",
        "        \"\"\"Load IoT data from server and return as DataFrame.\"\"\"\n",
        "        data = cls.fetch_from_server(feed, limit)\n",
        "        \n",
        "        if not data or \"data\" not in data or not data[\"data\"]:\n",
        "            return None\n",
        "        \n",
        "        df = pd.DataFrame(data[\"data\"])\n",
        "        \n",
        "        if \"created_at\" not in df.columns or \"value\" not in df.columns:\n",
        "            return None\n",
        "        \n",
        "        df[\"created_at\"] = df[\"created_at\"].apply(lambda x: parse_timestamp(x, 'server'))\n",
        "        df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
        "        df = df.dropna(subset=[\"created_at\", \"value\"])\n",
        "        df = df.sort_values(\"created_at\")\n",
        "        \n",
        "        return df if not df.empty else None\n",
        "    \n",
        "    @classmethod\n",
        "    def load_all_sensors(cls, limit: int = 50) -> Dict[str, Optional[pd.DataFrame]]:\n",
        "        \"\"\"Load all sensor types from server.\"\"\"\n",
        "        sensors = {}\n",
        "        for sensor_type in ['temperature', 'humidity', 'soil']:\n",
        "            sensors[sensor_type] = cls.load_iot_data(sensor_type, limit)\n",
        "        return sensors\n",
        "    \n",
        "    @classmethod\n",
        "    def sync_from_server(cls) -> Tuple[str, int]:\n",
        "        \"\"\"Sync new data from server to Firebase.\"\"\"\n",
        "        messages = [\"Starting sync...\"]\n",
        "        \n",
        "        latest = FirebaseService.get_latest_timestamp()\n",
        "        messages.append(f\"Latest in Firebase: {latest}\" if latest else \"No existing data\")\n",
        "        \n",
        "        server_data = cls.fetch_from_server()\n",
        "        \n",
        "        if not server_data or \"data\" not in server_data:\n",
        "            return \"\\n\".join(messages + [\"Error fetching from server\"]), 0\n",
        "        \n",
        "        # Filter new records\n",
        "        new_records = []\n",
        "        for sample in server_data[\"data\"]:\n",
        "            if not latest or sample[\"created_at\"] > latest:\n",
        "                new_records.append(sample)\n",
        "        \n",
        "        if not new_records:\n",
        "            return \"\\n\".join(messages + [\"No new data to sync\"]), 0\n",
        "        \n",
        "        # Save new records\n",
        "        saved = 0\n",
        "        for sample in new_records:\n",
        "            try:\n",
        "                vals = json.loads(sample['value'])\n",
        "                record = {\n",
        "                    'created_at': sample['created_at'],\n",
        "                    'temperature': vals.get('temperature', 0),\n",
        "                    'humidity': vals.get('humidity', 0),\n",
        "                    'soil': vals.get('soil', 0)\n",
        "                }\n",
        "                if FirebaseService.save_sensor_reading(record):\n",
        "                    saved += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Error saving record: {e}\")\n",
        "                continue\n",
        "        \n",
        "        messages.append(f\"Found {len(new_records)} new records\")\n",
        "        messages.append(f\"Saved {saved} records!\")\n",
        "        return \"\\n\".join(messages), saved\n",
        "\n",
        "\n",
        "# Backward-compatible functions\n",
        "def load_iot_data(feed: str, limit: int) -> Optional[pd.DataFrame]:\n",
        "    \"\"\"Backward compatible function.\"\"\"\n",
        "    return DataService.load_iot_data(feed, limit)\n",
        "\n",
        "def sync_new_data_from_server():\n",
        "    \"\"\"Backward compatible function.\"\"\"\n",
        "    return DataService.sync_from_server()\n",
        "\n",
        "print(\"\u2705 Data Service ready\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udf3f 7. Plant Analysis Service"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# PLANT ANALYSIS SERVICE\n",
        "# =============================================================================\n",
        "\n",
        "# Initialize ML classifier\n",
        "try:\n",
        "    clf = pipeline(\"image-classification\", model=PLANT_DISEASE_MODEL)\n",
        "    print(f\"\u2705 Plant disease model loaded: {PLANT_DISEASE_MODEL}\")\n",
        "except Exception as e:\n",
        "    print(f\"\u26a0\ufe0f Could not load plant disease model: {e}\")\n",
        "    clf = None\n",
        "\n",
        "\n",
        "class PlantAnalysisService:\n",
        "    \"\"\"Plant health analysis and disease detection.\"\"\"\n",
        "    \n",
        "    @classmethod\n",
        "    def analyze_sensor_status(cls, sensors: Dict[str, Optional[pd.DataFrame]]) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyze plant status from sensor data.\n",
        "        Returns status dict with issues and warnings.\n",
        "        \"\"\"\n",
        "        result = {\n",
        "            'status': 'unknown',\n",
        "            'status_emoji': '\u2753',\n",
        "            'issues': [],\n",
        "            'warnings': [],\n",
        "            'values': {},\n",
        "            'details': ''\n",
        "        }\n",
        "        \n",
        "        # Check for missing sensors\n",
        "        missing = [k for k, v in sensors.items() if v is None or v.empty]\n",
        "        if missing:\n",
        "            result['status'] = 'partial'\n",
        "            result['status_emoji'] = '\u26a0\ufe0f'\n",
        "            result['details'] = f\"Missing sensors: {', '.join(missing)}\"\n",
        "            return result\n",
        "        \n",
        "        # Get latest values\n",
        "        for sensor_type, df in sensors.items():\n",
        "            if df is not None and not df.empty:\n",
        "                value = float(df[\"value\"].iloc[-1])\n",
        "                result['values'][sensor_type] = value\n",
        "                \n",
        "                is_ok, is_warning, message = check_optimal_range(value, sensor_type)\n",
        "                \n",
        "                if not is_ok:\n",
        "                    result['issues'].append(message)\n",
        "                elif is_warning:\n",
        "                    result['warnings'].append(message)\n",
        "        \n",
        "        # Determine overall status\n",
        "        if result['issues']:\n",
        "            result['status'] = 'bad'\n",
        "            result['status_emoji'] = '\ud83d\udd34'\n",
        "            result['details'] = ' ; '.join(result['issues'])\n",
        "        elif result['warnings']:\n",
        "            result['status'] = 'warning'\n",
        "            result['status_emoji'] = '\ud83d\udfe1'\n",
        "            result['details'] = ' ; '.join(result['warnings'])\n",
        "        else:\n",
        "            result['status'] = 'ok'\n",
        "            result['status_emoji'] = '\ud83d\udfe2'\n",
        "            result['details'] = 'All sensors within optimal range'\n",
        "        \n",
        "        return result\n",
        "    \n",
        "    @classmethod\n",
        "    def analyze_image(cls, image_path: str, temp: float, humidity: float, \n",
        "                      soil: float) -> Tuple[str, str, str, str]:\n",
        "        \"\"\"\n",
        "        Analyze plant image for disease detection.\n",
        "        Returns: (diagnosis, status_html, alerts, recommendations)\n",
        "        \"\"\"\n",
        "        if clf is None:\n",
        "            return \"Model not available\", \"\", \"Error: Model not loaded\", \"\"\n",
        "        \n",
        "        # Run image classification\n",
        "        preds = clf(image_path)\n",
        "        top = preds[0]\n",
        "        label = top[\"label\"]\n",
        "        score = top[\"score\"]\n",
        "        \n",
        "        # Analyze sensor conditions\n",
        "        alerts = []\n",
        "        advice = []\n",
        "        \n",
        "        soil_ok, soil_warn, soil_msg = check_optimal_range(soil, 'soil')\n",
        "        if not soil_ok or soil_warn:\n",
        "            alerts.append(f\"Soil moisture: {soil_msg}\")\n",
        "            if soil < PLANT_OPTIMAL_RANGES['soil']['min']:\n",
        "                advice.append(\"Water the plant\")\n",
        "        \n",
        "        hum_ok, hum_warn, hum_msg = check_optimal_range(humidity, 'humidity')\n",
        "        if not hum_ok:\n",
        "            alerts.append(f\"Humidity: {hum_msg}\")\n",
        "            if humidity > PLANT_OPTIMAL_RANGES['humidity']['max']:\n",
        "                advice.append(\"Improve ventilation to reduce fungal risk\")\n",
        "        \n",
        "        temp_ok, temp_warn, temp_msg = check_optimal_range(temp, 'temperature')\n",
        "        if not temp_ok:\n",
        "            alerts.append(f\"Temperature: {temp_msg}\")\n",
        "            if temp > PLANT_OPTIMAL_RANGES['temperature']['max']:\n",
        "                advice.append(\"Move plant to shaded area\")\n",
        "        \n",
        "        # Determine status from image\n",
        "        is_healthy = \"healthy\" in label.lower()\n",
        "        \n",
        "        status_html = f'''\n",
        "        <div style=\"padding:10px;border-radius:10px;\n",
        "            background:{'#ddffdd' if is_healthy else '#ffdddd'};\n",
        "            border:1px solid {'#00aa00' if is_healthy else '#ff0000'};\n",
        "            font-weight:700;\">\n",
        "            {'\ud83d\udfe2 Plant status: HEALTHY' if is_healthy else '\ud83d\udd34 Plant status: DISEASE DETECTED'}\n",
        "        </div>\n",
        "        '''\n",
        "        \n",
        "        diagnosis = f\"Detected: {label} ({score:.2%})\"\n",
        "        alerts_text = \"\\n\".join(alerts) if alerts else \"No sensor alerts\"\n",
        "        advice_text = \"\\n\".join(advice) if advice else \"No immediate actions needed\"\n",
        "        \n",
        "        return diagnosis, status_html, alerts_text, advice_text\n",
        "\n",
        "\n",
        "def analyze_plant(image, temp, humidity, soil):\n",
        "    \"\"\"Backward compatible function.\"\"\"\n",
        "    return PlantAnalysisService.analyze_image(image, temp, humidity, soil)\n",
        "\n",
        "\n",
        "def plant_dashboard(limit: int):\n",
        "    \"\"\"Generate complete plant dashboard.\"\"\"\n",
        "    sensors = DataService.load_all_sensors(limit)\n",
        "    status = PlantAnalysisService.analyze_sensor_status(sensors)\n",
        "    \n",
        "    if status['status'] == 'partial':\n",
        "        return (\n",
        "            f\"{status['status_emoji']} Partial Data\",\n",
        "            status['details'],\n",
        "            None, None, None, None\n",
        "        )\n",
        "    \n",
        "    # Create plots\n",
        "    plots = {}\n",
        "    for sensor_type, df in sensors.items():\n",
        "        if df is not None and not df.empty:\n",
        "            fig = go.Figure()\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=df[\"created_at\"],\n",
        "                y=df[\"value\"],\n",
        "                mode=\"lines+markers\",\n",
        "                name=sensor_type.title(),\n",
        "                line=dict(color=COLORS.get(sensor_type, '#000'))\n",
        "            ))\n",
        "            fig.update_layout(\n",
        "                title=f\"{sensor_type.title()} Over Time\",\n",
        "                xaxis_title=\"Time\",\n",
        "                yaxis_title=f\"{sensor_type.title()} ({SENSOR_VALIDATION_RANGES[sensor_type]['unit']})\",\n",
        "                height=300\n",
        "            )\n",
        "            plots[sensor_type] = fig\n",
        "    \n",
        "    # Combined normalized plot\n",
        "    combined_fig = go.Figure()\n",
        "    for sensor_type, df in sensors.items():\n",
        "        if df is not None and not df.empty:\n",
        "            combined_fig.add_trace(go.Scatter(\n",
        "                x=df[\"created_at\"],\n",
        "                y=normalize_series(df[\"value\"]),\n",
        "                mode=\"lines\",\n",
        "                name=sensor_type.title(),\n",
        "                line=dict(color=COLORS.get(sensor_type, '#000'))\n",
        "            ))\n",
        "    combined_fig.update_layout(\n",
        "        title=\"All Sensors (Normalized)\",\n",
        "        xaxis_title=\"Time\",\n",
        "        yaxis_title=\"Normalized Value (0-1)\",\n",
        "        height=300\n",
        "    )\n",
        "    \n",
        "    # Build details text\n",
        "    values = status['values']\n",
        "    details = (\n",
        "        f\"{status['details']}\\n\\n\"\n",
        "        f\"Latest readings:\\n\"\n",
        "        f\"  \ud83c\udf21\ufe0f Temperature: {values.get('temperature', 'N/A'):.1f}\u00b0C\\n\"\n",
        "        f\"  \ud83d\udca7 Humidity: {values.get('humidity', 'N/A'):.1f}%\\n\"\n",
        "        f\"  \ud83c\udf31 Soil: {values.get('soil', 'N/A'):.1f}%\"\n",
        "    )\n",
        "    \n",
        "    return (\n",
        "        f\"{status['status_emoji']} Plant Status: {status['status'].upper()}\",\n",
        "        details,\n",
        "        plots.get('temperature'),\n",
        "        plots.get('humidity'),\n",
        "        plots.get('soil'),\n",
        "        combined_fig\n",
        "    )\n",
        "\n",
        "print(\"\u2705 Plant Analysis Service ready\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83e\udd16 8. RAG Service (Search & Retrieval)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# RAG SERVICE - Document indexing and retrieval\n",
        "# =============================================================================\n",
        "\n",
        "# Initialize NLP tools\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "# Global state for RAG\n",
        "_rag_state = {\n",
        "    'public_index': None,\n",
        "    'doc_map': None,\n",
        "    'doc_text': {},\n",
        "    'doc_text_cache': {},\n",
        "    'generator': None\n",
        "}\n",
        "\n",
        "\n",
        "class RAGService:\n",
        "    \"\"\"Retrieval-Augmented Generation service.\"\"\"\n",
        "    \n",
        "    INDEX_PATH = \"indexes/public_index\"\n",
        "    MAP_PATH = \"indexes/doc_map\"\n",
        "    TEXT_PATH = \"indexes/doc_text\"\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # NLP Preprocessing\n",
        "    # -------------------------------------------------------------------------\n",
        "    @staticmethod\n",
        "    def tokenize(text: str) -> List[str]:\n",
        "        \"\"\"Tokenize text into words.\"\"\"\n",
        "        return re.findall(r\"\\w+\", (text or \"\").lower())\n",
        "    \n",
        "    @staticmethod\n",
        "    def remove_stopwords(tokens: List[str]) -> List[str]:\n",
        "        \"\"\"Remove stop words.\"\"\"\n",
        "        return [t for t in tokens if t not in stop_words]\n",
        "    \n",
        "    @staticmethod\n",
        "    def apply_stemming(tokens: List[str]) -> List[str]:\n",
        "        \"\"\"Apply Porter stemming.\"\"\"\n",
        "        return [stemmer.stem(t) for t in tokens]\n",
        "    \n",
        "    @classmethod\n",
        "    def preprocess(cls, text: str) -> List[str]:\n",
        "        \"\"\"Full preprocessing pipeline.\"\"\"\n",
        "        tokens = cls.tokenize(text)\n",
        "        tokens = cls.remove_stopwords(tokens)\n",
        "        tokens = cls.apply_stemming(tokens)\n",
        "        return tokens\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # Index Operations\n",
        "    # -------------------------------------------------------------------------\n",
        "    @classmethod\n",
        "    def build_inverted_index(cls, urls: List[str], doc_texts: Dict) -> Tuple[Dict, Dict]:\n",
        "        \"\"\"Build inverted index from documents.\"\"\"\n",
        "        inverted = defaultdict(set)\n",
        "        doc_map = {i: url for i, url in enumerate(urls)}\n",
        "        \n",
        "        for doc_id in range(len(urls)):\n",
        "            text = doc_texts.get(doc_id) or doc_texts.get(str(doc_id)) or \"\"\n",
        "            tokens = cls.preprocess(text)\n",
        "            \n",
        "            for term in set(tokens):\n",
        "                inverted[term].add(doc_id)\n",
        "        \n",
        "        # Convert to sorted lists\n",
        "        inverted = {term: sorted(list(ids)) for term, ids in inverted.items()}\n",
        "        return inverted, doc_map\n",
        "    \n",
        "    @classmethod\n",
        "    def load_index(cls, load_text: bool = False) -> bool:\n",
        "        \"\"\"Load index from Firebase.\"\"\"\n",
        "        try:\n",
        "            _rag_state['public_index'] = FirebaseService.http_get(cls.INDEX_PATH) or {}\n",
        "            _rag_state['doc_map'] = FirebaseService.http_get(cls.MAP_PATH) or {}\n",
        "            \n",
        "            # Normalize doc_map\n",
        "            if isinstance(_rag_state['doc_map'], list):\n",
        "                _rag_state['doc_map'] = {str(i): v for i, v in enumerate(_rag_state['doc_map'])}\n",
        "            \n",
        "            if load_text:\n",
        "                _rag_state['doc_text'] = FirebaseService.http_get(cls.TEXT_PATH) or {}\n",
        "            \n",
        "            print(f\"Loaded index: {len(_rag_state['public_index'])} terms, {len(_rag_state['doc_map'])} docs\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading index: {e}\")\n",
        "            return False\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # Search Operations\n",
        "    # -------------------------------------------------------------------------\n",
        "    @classmethod\n",
        "    def search(cls, query: str, k: int = 3) -> Tuple[List[str], List[Dict]]:\n",
        "        \"\"\"Search for documents matching query.\"\"\"\n",
        "        if _rag_state['public_index'] is None:\n",
        "            cls.load_index()\n",
        "        \n",
        "        q_terms = cls.preprocess(query)\n",
        "        scores = defaultdict(int)\n",
        "        \n",
        "        for term in q_terms:\n",
        "            for doc_id in (_rag_state['public_index'].get(term, []) or []):\n",
        "                scores[int(doc_id)] += 1\n",
        "        \n",
        "        ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:k]\n",
        "        \n",
        "        results = []\n",
        "        for doc_id, score in ranked:\n",
        "            url = _rag_state['doc_map'].get(str(doc_id))\n",
        "            results.append({\"doc_id\": doc_id, \"score\": score, \"url\": url})\n",
        "        \n",
        "        return q_terms, results\n",
        "    \n",
        "    @classmethod\n",
        "    def get_doc_text(cls, doc_id: int) -> str:\n",
        "        \"\"\"Get document text with caching.\"\"\"\n",
        "        key = str(int(doc_id))\n",
        "        \n",
        "        if key in _rag_state['doc_text_cache']:\n",
        "            return _rag_state['doc_text_cache'][key] or \"\"\n",
        "        \n",
        "        try:\n",
        "            txt = FirebaseService.http_get(f\"{cls.TEXT_PATH}/{key}\")\n",
        "            if txt is None:\n",
        "                txt = \"\"\n",
        "            if not isinstance(txt, str):\n",
        "                txt = str(txt)\n",
        "            _rag_state['doc_text_cache'][key] = txt\n",
        "            return txt\n",
        "        except Exception:\n",
        "            return \"\"\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # Generation\n",
        "    # -------------------------------------------------------------------------\n",
        "    @classmethod\n",
        "    def init_generator(cls):\n",
        "        \"\"\"Initialize text generation model.\"\"\"\n",
        "        if _rag_state['generator'] is not None:\n",
        "            return\n",
        "        \n",
        "        try:\n",
        "            import torch\n",
        "            device = 0 if torch.cuda.is_available() else -1\n",
        "            \n",
        "            try:\n",
        "                _rag_state['generator'] = pipeline(\n",
        "                    \"text2text-generation\",\n",
        "                    model=RAG_MODEL_PRIMARY,\n",
        "                    device=device\n",
        "                )\n",
        "                print(f\"\u2705 RAG model loaded: {RAG_MODEL_PRIMARY}\")\n",
        "            except Exception:\n",
        "                _rag_state['generator'] = pipeline(\n",
        "                    \"text2text-generation\",\n",
        "                    model=RAG_MODEL_FALLBACK,\n",
        "                    device=device\n",
        "                )\n",
        "                print(f\"\u2705 RAG model loaded (fallback): {RAG_MODEL_FALLBACK}\")\n",
        "        except Exception as e:\n",
        "            print(f\"\u26a0\ufe0f Could not load RAG model: {e}\")\n",
        "            _rag_state['generator'] = None\n",
        "    \n",
        "    @classmethod\n",
        "    def generate_answer(cls, query: str, k: int = 3) -> Tuple[List[str], List[Dict], str]:\n",
        "        \"\"\"Generate answer using RAG.\"\"\"\n",
        "        cls.init_generator()\n",
        "        \n",
        "        q_terms, results = cls.search(query, k)\n",
        "        \n",
        "        if not results:\n",
        "            return q_terms, results, \"No documents matched the query.\"\n",
        "        \n",
        "        # Build context\n",
        "        context_parts = []\n",
        "        for r in results[:3]:\n",
        "            doc_text = cls.get_doc_text(r['doc_id'])\n",
        "            snippet = doc_text[:RAG_SNIPPET_CHARS] if doc_text else \"\"\n",
        "            context_parts.append(f\"[Doc {r['doc_id']}]: {snippet}\")\n",
        "        \n",
        "        context = \"\\n\".join(context_parts)\n",
        "        \n",
        "        if _rag_state['generator'] is None:\n",
        "            return q_terms, results, f\"Based on documents: {context[:500]}...\"\n",
        "        \n",
        "        prompt = (\n",
        "            \"Answer the question using ONLY the provided context.\\n\"\n",
        "            \"Be concise (1-3 sentences). Cite sources as [Doc X].\\n\\n\"\n",
        "            f\"Question: {query}\\n\\n\"\n",
        "            f\"Context:\\n{context}\\n\\n\"\n",
        "            \"Answer:\"\n",
        "        )\n",
        "        \n",
        "        try:\n",
        "            out = _rag_state['generator'](\n",
        "                prompt,\n",
        "                max_new_tokens=RAG_MAX_NEW_TOKENS,\n",
        "                do_sample=False,\n",
        "                num_beams=1\n",
        "            )[0][\"generated_text\"]\n",
        "            return q_terms, results, out.strip()\n",
        "        except Exception as e:\n",
        "            return q_terms, results, f\"Generation error: {e}\"\n",
        "\n",
        "\n",
        "# Initialize RAG\n",
        "RAGService.load_index()\n",
        "RAGService.init_generator()\n",
        "\n",
        "# Backward-compatible functions\n",
        "def preprocess_query(query: str):\n",
        "    return RAGService.preprocess(query)\n",
        "\n",
        "def search_top_k(query: str, k: int = 3):\n",
        "    return RAGService.search(query, k)\n",
        "\n",
        "def rag_generate_answer(query: str, k: int = 3, snippet_chars: int = 160):\n",
        "    return RAGService.generate_answer(query, k)\n",
        "\n",
        "def get_doc_text(doc_id: int) -> str:\n",
        "    return RAGService.get_doc_text(doc_id)\n",
        "\n",
        "# Aliases for existing variable names\n",
        "public_index = _rag_state['public_index']\n",
        "doc_map = _rag_state['doc_map']\n",
        "gen = _rag_state['generator']\n",
        "\n",
        "print(\"\u2705 RAG Service ready\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcc8 9. Visualization Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# VISUALIZATION FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "class Visualizations:\n",
        "    \"\"\"Chart and visualization generators.\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def create_kpi_card(label: str, value: float, unit: str, \n",
        "                        change: float = 0, trend: str = \"up\",\n",
        "                        color: str = None) -> str:\n",
        "        \"\"\"Create KPI card HTML.\"\"\"\n",
        "        color = color or COLORS['temperature']\n",
        "        icon = \"\u2191\" if trend == \"up\" else (\"\u2193\" if trend == \"down\" else \"\u2192\")\n",
        "        trend_class = f\"trend-{trend}\"\n",
        "        \n",
        "        return f'''\n",
        "        <div class=\"kpi-card\" style=\"border-left: 4px solid {color}; \n",
        "             background: white; padding: 20px; border-radius: 10px; \n",
        "             box-shadow: 0 2px 4px rgba(0,0,0,0.1); text-align: center;\">\n",
        "            <p style=\"color: #666; font-size: 14px; margin: 0;\">{label}</p>\n",
        "            <p style=\"font-size: 36px; font-weight: bold; margin: 10px 0;\">\n",
        "                {value:.1f}<span style=\"font-size: 18px;\">{unit}</span>\n",
        "            </p>\n",
        "            <p style=\"color: {'#10b981' if trend == 'up' else '#ef4444'}; font-size: 12px;\">\n",
        "                {icon} {change:.1f} from avg\n",
        "            </p>\n",
        "        </div>\n",
        "        '''\n",
        "    \n",
        "    @staticmethod\n",
        "    def create_time_series(df: pd.DataFrame) -> go.Figure:\n",
        "        \"\"\"Create time series plot for all sensors.\"\"\"\n",
        "        fig = make_subplots(rows=3, cols=1, shared_xaxes=True,\n",
        "                          subplot_titles=('Temperature', 'Humidity', 'Soil Moisture'),\n",
        "                          vertical_spacing=0.08)\n",
        "        \n",
        "        sensors = [\n",
        "            ('temperature', '\u00b0C', COLORS['temperature']),\n",
        "            ('humidity', '%', COLORS['humidity']),\n",
        "            ('soil', '%', COLORS['soil'])\n",
        "        ]\n",
        "        \n",
        "        for i, (col, unit, color) in enumerate(sensors, 1):\n",
        "            if col in df.columns:\n",
        "                fig.add_trace(\n",
        "                    go.Scatter(x=df['timestamp'], y=df[col],\n",
        "                              mode='lines+markers', name=col.title(),\n",
        "                              line=dict(color=color)),\n",
        "                    row=i, col=1\n",
        "                )\n",
        "        \n",
        "        fig.update_layout(height=600, showlegend=True,\n",
        "                         title_text=\"Sensor Readings Over Time\")\n",
        "        return fig\n",
        "    \n",
        "    @staticmethod\n",
        "    def create_correlation_matrix(df: pd.DataFrame) -> Tuple[str, go.Figure]:\n",
        "        \"\"\"Create correlation matrix.\"\"\"\n",
        "        cols = ['temperature', 'humidity', 'soil']\n",
        "        available = [c for c in cols if c in df.columns]\n",
        "        \n",
        "        if len(available) < 2:\n",
        "            return \"Not enough data\", None\n",
        "        \n",
        "        corr = df[available].corr()\n",
        "        \n",
        "        fig = go.Figure(data=go.Heatmap(\n",
        "            z=corr.values,\n",
        "            x=available,\n",
        "            y=available,\n",
        "            colorscale='RdBu',\n",
        "            zmid=0,\n",
        "            text=[[f'{v:.2f}' for v in row] for row in corr.values],\n",
        "            texttemplate='%{text}',\n",
        "            textfont={\"size\": 14}\n",
        "        ))\n",
        "        \n",
        "        fig.update_layout(title=\"Sensor Correlations\", height=400)\n",
        "        \n",
        "        explanation = \"Shows relationships between sensors. Values near 1 or -1 indicate strong correlation.\"\n",
        "        return explanation, fig\n",
        "    \n",
        "    @staticmethod\n",
        "    def create_hourly_patterns(df: pd.DataFrame) -> Tuple[str, go.Figure]:\n",
        "        \"\"\"Create hourly aggregation chart.\"\"\"\n",
        "        if 'timestamp' not in df.columns:\n",
        "            return \"No timestamp data\", None\n",
        "        \n",
        "        df_copy = df.copy()\n",
        "        df_copy['hour'] = df_copy['timestamp'].dt.hour\n",
        "        \n",
        "        hourly = df_copy.groupby('hour')[['temperature', 'humidity', 'soil']].mean()\n",
        "        \n",
        "        fig = go.Figure()\n",
        "        for col, color in [('temperature', COLORS['temperature']), \n",
        "                          ('humidity', COLORS['humidity']),\n",
        "                          ('soil', COLORS['soil'])]:\n",
        "            if col in hourly.columns:\n",
        "                fig.add_trace(go.Scatter(\n",
        "                    x=hourly.index, y=hourly[col],\n",
        "                    mode='lines+markers', name=col.title(),\n",
        "                    line=dict(color=color)\n",
        "                ))\n",
        "        \n",
        "        fig.update_layout(\n",
        "            title=\"Average Values by Hour\",\n",
        "            xaxis_title=\"Hour (0-23)\",\n",
        "            yaxis_title=\"Value\",\n",
        "            height=400\n",
        "        )\n",
        "        \n",
        "        return \"Shows daily patterns in sensor readings\", fig\n",
        "    \n",
        "    @staticmethod\n",
        "    def create_distribution(df: pd.DataFrame) -> Tuple[str, go.Figure]:\n",
        "        \"\"\"Create distribution histograms.\"\"\"\n",
        "        fig = make_subplots(rows=1, cols=3,\n",
        "                          subplot_titles=('Temperature', 'Humidity', 'Soil'))\n",
        "        \n",
        "        for i, (col, color) in enumerate([\n",
        "            ('temperature', COLORS['temperature']),\n",
        "            ('humidity', COLORS['humidity']),\n",
        "            ('soil', COLORS['soil'])\n",
        "        ], 1):\n",
        "            if col in df.columns:\n",
        "                fig.add_trace(\n",
        "                    go.Histogram(x=df[col], name=col.title(),\n",
        "                               marker_color=color, opacity=0.7),\n",
        "                    row=1, col=i\n",
        "                )\n",
        "        \n",
        "        fig.update_layout(height=350, showlegend=False,\n",
        "                         title_text=\"Value Distributions\")\n",
        "        \n",
        "        return \"Distribution of sensor values\", fig\n",
        "    \n",
        "    @staticmethod\n",
        "    def create_moving_average(df: pd.DataFrame, variable: str) -> Tuple[str, go.Figure]:\n",
        "        \"\"\"Create moving average plot.\"\"\"\n",
        "        if variable not in df.columns:\n",
        "            return f\"Variable {variable} not found\", None\n",
        "        \n",
        "        df_sorted = df.sort_values('timestamp').copy()\n",
        "        \n",
        "        fig = go.Figure()\n",
        "        \n",
        "        # Raw data\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=df_sorted['timestamp'], y=df_sorted[variable],\n",
        "            mode='lines', name='Raw', opacity=0.5,\n",
        "            line=dict(color='gray')\n",
        "        ))\n",
        "        \n",
        "        # Moving averages\n",
        "        for window, color in [(5, '#3b82f6'), (10, '#ef4444'), (20, '#10b981')]:\n",
        "            if len(df_sorted) >= window:\n",
        "                ma = df_sorted[variable].rolling(window=window).mean()\n",
        "                fig.add_trace(go.Scatter(\n",
        "                    x=df_sorted['timestamp'], y=ma,\n",
        "                    mode='lines', name=f'MA-{window}',\n",
        "                    line=dict(color=color, width=2)\n",
        "                ))\n",
        "        \n",
        "        fig.update_layout(\n",
        "            title=f\"Moving Averages - {variable.title()}\",\n",
        "            height=400\n",
        "        )\n",
        "        \n",
        "        return \"Smoothed trends over time\", fig\n",
        "\n",
        "\n",
        "# Backward-compatible functions\n",
        "def create_kpi_cards(df):\n",
        "    if df.empty:\n",
        "        return \"<p>No data</p>\"\n",
        "    \n",
        "    cards = []\n",
        "    for col, color in [('temperature', COLORS['temperature']),\n",
        "                       ('humidity', COLORS['humidity']),\n",
        "                       ('soil', COLORS['soil'])]:\n",
        "        if col in df.columns:\n",
        "            current = df[col].iloc[-1]\n",
        "            avg = df[col].mean()\n",
        "            unit = SENSOR_VALIDATION_RANGES[col]['unit']\n",
        "            cards.append(Visualizations.create_kpi_card(\n",
        "                col.title(), current, unit, current - avg, \n",
        "                \"up\" if current > avg else \"down\", color\n",
        "            ))\n",
        "    \n",
        "    return f'<div style=\"display: grid; grid-template-columns: repeat(3, 1fr); gap: 20px;\">{\" \".join(cards)}</div>'\n",
        "\n",
        "\n",
        "def create_stat_cards_html(df):\n",
        "    if df.empty:\n",
        "        return \"<p>No data</p>\"\n",
        "    \n",
        "    stats = []\n",
        "    for col in ['temperature', 'humidity', 'soil']:\n",
        "        if col in df.columns:\n",
        "            stats.append(f'''\n",
        "            <div style=\"padding: 15px; background: #f5f5f5; border-radius: 8px;\">\n",
        "                <b>{col.title()}</b><br>\n",
        "                Min: {df[col].min():.1f} | Max: {df[col].max():.1f} | Avg: {df[col].mean():.1f}\n",
        "            </div>\n",
        "            ''')\n",
        "    \n",
        "    return f'<div style=\"display: grid; grid-template-columns: repeat(3, 1fr); gap: 15px;\">{\" \".join(stats)}</div>'\n",
        "\n",
        "\n",
        "def create_time_series_plot(df):\n",
        "    return Visualizations.create_time_series(df)\n",
        "\n",
        "\n",
        "def calculate_correlations(df):\n",
        "    return Visualizations.create_correlation_matrix(df)\n",
        "\n",
        "\n",
        "def hourly_patterns(df):\n",
        "    return Visualizations.create_hourly_patterns(df)\n",
        "\n",
        "\n",
        "def daily_patterns(df):\n",
        "    if df.empty:\n",
        "        return \"No data\", None\n",
        "    df_copy = df.copy()\n",
        "    df_copy['date'] = df_copy['timestamp'].dt.date\n",
        "    daily = df_copy.groupby('date')[['temperature', 'humidity', 'soil']].mean()\n",
        "    \n",
        "    fig = go.Figure()\n",
        "    for col, color in [('temperature', COLORS['temperature']),\n",
        "                       ('humidity', COLORS['humidity']),\n",
        "                       ('soil', COLORS['soil'])]:\n",
        "        if col in daily.columns:\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=[str(d) for d in daily.index], y=daily[col],\n",
        "                mode='lines+markers', name=col.title(),\n",
        "                line=dict(color=color)\n",
        "            ))\n",
        "    fig.update_layout(title=\"Daily Averages\", height=400)\n",
        "    return \"Daily average values\", fig\n",
        "\n",
        "\n",
        "def distribution_analysis(df):\n",
        "    return Visualizations.create_distribution(df)\n",
        "\n",
        "\n",
        "def time_series_decomposition(df, variable):\n",
        "    return Visualizations.create_moving_average(df, variable)\n",
        "\n",
        "\n",
        "print(\"\u2705 Visualization functions loaded\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcc4 10. Report Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# REPORT GENERATOR\n",
        "# =============================================================================\n",
        "\n",
        "class ReportGenerator:\n",
        "    \"\"\"Generate DOCX reports from sensor data.\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def create_report(df: pd.DataFrame) -> str:\n",
        "        \"\"\"Create a DOCX report and return the file path.\"\"\"\n",
        "        if df is None or df.empty:\n",
        "            raise ValueError(\"No data available for report\")\n",
        "        \n",
        "        doc = Document()\n",
        "        \n",
        "        # Title\n",
        "        title = doc.add_heading(\"CloudGarden Plant Health Report\", level=0)\n",
        "        title.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "        \n",
        "        # Date\n",
        "        date_para = doc.add_paragraph()\n",
        "        date_para.add_run(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
        "        date_para.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "        \n",
        "        doc.add_paragraph()\n",
        "        \n",
        "        # Executive Summary\n",
        "        doc.add_heading(\"Executive Summary\", level=1)\n",
        "        \n",
        "        # Analyze data\n",
        "        issues = []\n",
        "        for col in ['temperature', 'humidity', 'soil']:\n",
        "            if col in df.columns:\n",
        "                avg = df[col].mean()\n",
        "                ranges = PLANT_OPTIMAL_RANGES.get(col, {})\n",
        "                if avg < ranges.get('min', 0):\n",
        "                    issues.append(f\"{col.title()} is low (avg: {avg:.1f})\")\n",
        "                elif avg > ranges.get('max', 100):\n",
        "                    issues.append(f\"{col.title()} is high (avg: {avg:.1f})\")\n",
        "        \n",
        "        if issues:\n",
        "            summary = \"Issues detected:\\n\" + \"\\n\".join(f\"- {i}\" for i in issues)\n",
        "        else:\n",
        "            summary = \"All environmental conditions are within optimal ranges.\"\n",
        "        \n",
        "        doc.add_paragraph(summary)\n",
        "        \n",
        "        # Environmental Conditions Table\n",
        "        doc.add_heading(\"Environmental Conditions\", level=1)\n",
        "        \n",
        "        table = doc.add_table(rows=1, cols=5)\n",
        "        table.style = 'Table Grid'\n",
        "        headers = table.rows[0].cells\n",
        "        headers[0].text = \"Sensor\"\n",
        "        headers[1].text = \"Current\"\n",
        "        headers[2].text = \"Average\"\n",
        "        headers[3].text = \"Min\"\n",
        "        headers[4].text = \"Max\"\n",
        "        \n",
        "        for col in ['temperature', 'humidity', 'soil']:\n",
        "            if col in df.columns:\n",
        "                row = table.add_row().cells\n",
        "                row[0].text = col.title()\n",
        "                row[1].text = f\"{df[col].iloc[-1]:.1f}\"\n",
        "                row[2].text = f\"{df[col].mean():.1f}\"\n",
        "                row[3].text = f\"{df[col].min():.1f}\"\n",
        "                row[4].text = f\"{df[col].max():.1f}\"\n",
        "        \n",
        "        # Statistics\n",
        "        doc.add_heading(\"Statistical Summary\", level=1)\n",
        "        \n",
        "        stats_text = f\"\"\"\n",
        "Data Points: {len(df)}\n",
        "Time Range: {df['timestamp'].min()} to {df['timestamp'].max()}\n",
        "\n",
        "Temperature: Mean={df['temperature'].mean():.1f}\u00b0C, Std={df['temperature'].std():.1f}\u00b0C\n",
        "Humidity: Mean={df['humidity'].mean():.1f}%, Std={df['humidity'].std():.1f}%\n",
        "Soil Moisture: Mean={df['soil'].mean():.1f}%, Std={df['soil'].std():.1f}%\n",
        "\"\"\"\n",
        "        doc.add_paragraph(stats_text)\n",
        "        \n",
        "        # Save to temp file\n",
        "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.docx')\n",
        "        doc.save(temp_file.name)\n",
        "        \n",
        "        return temp_file.name\n",
        "\n",
        "\n",
        "def generate_report_screen(samples: int):\n",
        "    \"\"\"Generate report from sensor data.\"\"\"\n",
        "    try:\n",
        "        # Load data\n",
        "        sensors = DataService.load_all_sensors(samples)\n",
        "        \n",
        "        # Combine sensor data\n",
        "        dfs = []\n",
        "        for sensor_type, df in sensors.items():\n",
        "            if df is not None and not df.empty:\n",
        "                df_renamed = df.rename(columns={'value': sensor_type, 'created_at': 'timestamp'})\n",
        "                dfs.append(df_renamed[['timestamp', sensor_type]])\n",
        "        \n",
        "        if not dfs:\n",
        "            return \"No data available\", None\n",
        "        \n",
        "        # Merge all sensors\n",
        "        combined = dfs[0]\n",
        "        for df in dfs[1:]:\n",
        "            combined = combined.merge(df, on='timestamp', how='outer')\n",
        "        combined = combined.sort_values('timestamp').reset_index(drop=True)\n",
        "        \n",
        "        # Generate report\n",
        "        file_path = ReportGenerator.create_report(combined)\n",
        "        \n",
        "        return f\"\u2705 Report generated with {len(combined)} data points\", file_path\n",
        "    \n",
        "    except Exception as e:\n",
        "        return f\"\u274c Error: {str(e)}\", None\n",
        "\n",
        "\n",
        "print(\"\u2705 Report Generator ready\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfa8 11. CSS Styles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# CSS STYLES\n",
        "# =============================================================================\n",
        "\n",
        "CUSTOM_CSS = \"\"\"\n",
        "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');\n",
        "* { font-family: 'Inter', sans-serif; }\n",
        "\n",
        ".kpi-card {\n",
        "    background: white;\n",
        "    padding: 24px;\n",
        "    border-radius: 12px;\n",
        "    box-shadow: 0 1px 3px rgba(0,0,0,0.12);\n",
        "    text-align: center;\n",
        "    border-left: 4px solid;\n",
        "}\n",
        "\n",
        ".kpi-label { color: #6b7280; font-size: 14px; font-weight: 600; }\n",
        ".kpi-value { font-size: 48px; font-weight: 700; color: #1f2937; }\n",
        ".trend-up { color: #10b981; }\n",
        ".trend-down { color: #ef4444; }\n",
        "\n",
        ".status-badge {\n",
        "    display: inline-flex;\n",
        "    align-items: center;\n",
        "    padding: 4px 12px;\n",
        "    border-radius: 16px;\n",
        "    font-size: 12px;\n",
        "    font-weight: 600;\n",
        "}\n",
        "\n",
        ".explanation-card {\n",
        "    padding: 16px;\n",
        "    border-radius: 8px;\n",
        "    margin: 10px 0;\n",
        "}\n",
        "\n",
        ".legend-card {\n",
        "    padding: 14px;\n",
        "    border: 1px solid var(--border-color-primary);\n",
        "    border-radius: 10px;\n",
        "    margin-top: 14px;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "print(\"\u2705 CSS loaded\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udda5\ufe0f 12. UI Components (Gradio Tabs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# UI COMPONENTS - TAB BUILDERS\n",
        "# =============================================================================\n",
        "\n",
        "def build_realtime_dashboard_tab():\n",
        "    \"\"\"Build the realtime plant dashboard tab.\"\"\"\n",
        "    gr.Markdown(\"<h3>\ud83c\udf3f Overall Plant Status (Real-Time)</h3>\")\n",
        "    \n",
        "    samples = gr.Slider(1, 200, value=20, step=1, label=\"Number of Samples\")\n",
        "    overall_btn = gr.Button(\"Update Plant Dashboard\", variant=\"primary\")\n",
        "    \n",
        "    overall_status = gr.Textbox(label=\"Overall Status\", lines=1)\n",
        "    overall_info = gr.Textbox(label=\"Status Details\", lines=4)\n",
        "    \n",
        "    with gr.Row():\n",
        "        gr.Markdown(f\"\"\"\n",
        "        <div class=\"legend-card\">\n",
        "            <h4>\ud83c\udf3f Plant Status</h4>\n",
        "            <span style=\"color:{STATUS_OK_COLOR};font-size:26px;\">\u25cf</span> <b>Healthy</b> - All values normal<br>\n",
        "            <span style=\"color:{STATUS_WARN_COLOR};font-size:26px;\">\u25cf</span> <b>Warning</b> - Near threshold<br>\n",
        "            <span style=\"color:{STATUS_BAD_COLOR};font-size:26px;\">\u25cf</span> <b>Not OK</b> - Out of range\n",
        "        </div>\n",
        "        \"\"\")\n",
        "        \n",
        "        gr.Markdown(f\"\"\"\n",
        "        <div class=\"legend-card\">\n",
        "            <h4>\u2139\ufe0f Valid Ranges</h4>\n",
        "            <span style=\"color:{COLOR_TEMP};font-size:26px;\">\u25cf</span> \ud83c\udf21\ufe0f Temperature: 18\u201332\u00b0C<br>\n",
        "            <span style=\"color:{COLOR_HUM};font-size:26px;\">\u25cf</span> \ud83d\udca7 Humidity: 35\u201375%<br>\n",
        "            <span style=\"color:{COLOR_SOIL};font-size:26px;\">\u25cf</span> \ud83c\udf31 Soil: 20\u201360%\n",
        "        </div>\n",
        "        \"\"\")\n",
        "    \n",
        "    gr.Markdown(\"<h2 style='text-align:center;'>\ud83d\udcc8 Plant Sensor Graphs</h2>\")\n",
        "    \n",
        "    with gr.Row():\n",
        "        plot_temp = gr.Plot(label=\"Temperature\")\n",
        "        plot_hum = gr.Plot(label=\"Humidity\")\n",
        "    \n",
        "    with gr.Row():\n",
        "        plot_soil = gr.Plot(label=\"Soil Moisture\")\n",
        "        plot_combined = gr.Plot(label=\"Combined (Normalized)\")\n",
        "    \n",
        "    overall_btn.click(\n",
        "        fn=plant_dashboard,\n",
        "        inputs=[samples],\n",
        "        outputs=[overall_status, overall_info, plot_temp, plot_hum, plot_soil, plot_combined]\n",
        "    )\n",
        "\n",
        "\n",
        "def build_iot_dashboard_tab():\n",
        "    \"\"\"Build the IoT analytics dashboard tab.\"\"\"\n",
        "    gr.Markdown(\"### \ud83d\udcc8 Comprehensive Sensor Analytics\")\n",
        "    \n",
        "    refresh_btn = gr.Button(\"\ud83d\udd04 Refresh All Data\", variant=\"primary\")\n",
        "    \n",
        "    # KPI Cards\n",
        "    gr.Markdown(\"#### \ud83d\udccc Current Readings\")\n",
        "    kpi_html = gr.HTML()\n",
        "    \n",
        "    # Statistics\n",
        "    gr.Markdown(\"#### \ud83d\udcca Statistical Summary\")\n",
        "    stats_html = gr.HTML()\n",
        "    \n",
        "    # Time Series\n",
        "    gr.Markdown(\"#### \ud83d\udcc8 Time Series\")\n",
        "    ts_plot = gr.Plot()\n",
        "    \n",
        "    # Correlation\n",
        "    gr.Markdown(\"#### \ud83d\udd17 Correlation Analysis\")\n",
        "    corr_card = gr.HTML()\n",
        "    corr_plot = gr.Plot()\n",
        "    \n",
        "    # Hourly Patterns\n",
        "    gr.Markdown(\"#### \u23f0 Hourly Patterns\")\n",
        "    hourly_card = gr.HTML()\n",
        "    hourly_plot = gr.Plot()\n",
        "    \n",
        "    # Daily Trends\n",
        "    gr.Markdown(\"#### \ud83d\udcc5 Daily Trends\")\n",
        "    daily_card = gr.HTML()\n",
        "    daily_plot = gr.Plot()\n",
        "    \n",
        "    # Distribution\n",
        "    gr.Markdown(\"#### \ud83d\udcca Distributions\")\n",
        "    dist_card = gr.HTML()\n",
        "    dist_plot = gr.Plot()\n",
        "    \n",
        "    # Moving Averages\n",
        "    gr.Markdown(\"#### \ud83d\udcc9 Moving Averages\")\n",
        "    with gr.Row():\n",
        "        ma_variable = gr.Dropdown(\n",
        "            choices=['temperature', 'humidity', 'soil'],\n",
        "            value='temperature',\n",
        "            label='Select Variable'\n",
        "        )\n",
        "        ma_btn = gr.Button(\"Generate\")\n",
        "    ma_card = gr.HTML()\n",
        "    ma_plot = gr.Plot()\n",
        "    \n",
        "    def dashboard_screen():\n",
        "        df = load_data_from_firebase()\n",
        "        if df.empty:\n",
        "            empty = \"<div style='padding:20px;text-align:center;'>No data. Click Sync Data!</div>\"\n",
        "            return empty, empty, None, empty, None, empty, None, empty, None, empty, None\n",
        "        \n",
        "        kpi = create_kpi_cards(df)\n",
        "        stats = create_stat_cards_html(df)\n",
        "        ts = create_time_series_plot(df)\n",
        "        corr_c, corr_p = calculate_correlations(df)\n",
        "        hour_c, hour_p = hourly_patterns(df)\n",
        "        day_c, day_p = daily_patterns(df)\n",
        "        dist_c, dist_p = distribution_analysis(df)\n",
        "        \n",
        "        return kpi, stats, ts, corr_c, corr_p, hour_c, hour_p, day_c, day_p, dist_c, dist_p\n",
        "    \n",
        "    def dashboard_ma(variable):\n",
        "        df = load_data_from_firebase()\n",
        "        if df.empty:\n",
        "            return \"No data\", None\n",
        "        return time_series_decomposition(df, variable)\n",
        "    \n",
        "    refresh_btn.click(\n",
        "        dashboard_screen,\n",
        "        outputs=[kpi_html, stats_html, ts_plot, corr_card, corr_plot,\n",
        "                hourly_card, hourly_plot, daily_card, daily_plot, dist_card, dist_plot]\n",
        "    )\n",
        "    \n",
        "    ma_btn.click(dashboard_ma, inputs=[ma_variable], outputs=[ma_card, ma_plot])\n",
        "\n",
        "\n",
        "def build_generate_report_tab():\n",
        "    \"\"\"Build the report generation tab.\"\"\"\n",
        "    gr.Markdown(\"## \ud83d\udcc4 Generate Report\")\n",
        "    gr.Markdown(\"Generate a Word (DOCX) report based on sensor data.\")\n",
        "    \n",
        "    report_samples = gr.Slider(5, 200, value=20, step=1, label=\"Samples per sensor\")\n",
        "    report_btn = gr.Button(\"\ud83d\udce5 Generate & Download Report\", variant=\"primary\")\n",
        "    report_status = gr.Textbox(label=\"Status\", lines=2)\n",
        "    report_file = gr.File(label=\"Download DOCX\")\n",
        "    \n",
        "    report_btn.click(\n",
        "        fn=generate_report_screen,\n",
        "        inputs=[report_samples],\n",
        "        outputs=[report_status, report_file]\n",
        "    )\n",
        "\n",
        "\n",
        "def build_plant_disease_detection_tab():\n",
        "    \"\"\"Build the plant disease detection tab.\"\"\"\n",
        "    gr.Markdown(\"## \ud83d\uddbc\ufe0f Plant Disease Detection\")\n",
        "    \n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            image = gr.Image(type=\"filepath\", label=\"Upload plant image\", sources=[\"upload\"])\n",
        "            temp = gr.Slider(0, 45, value=25, label=\"Temperature (\u00b0C)\")\n",
        "            humidity = gr.Slider(0, 100, value=50, label=\"Humidity (%)\")\n",
        "            soil = gr.Slider(0, 100, value=50, label=\"Soil Moisture (%)\")\n",
        "            run_btn = gr.Button(\"Analyze Plant\", variant=\"primary\")\n",
        "        \n",
        "        with gr.Column(scale=2):\n",
        "            diagnosis = gr.Textbox(label=\"Diagnosis\")\n",
        "            status = gr.HTML(label=\"Status\")\n",
        "            alerts = gr.Textbox(label=\"Alerts\", lines=5)\n",
        "            recommendations = gr.Textbox(label=\"Recommendations\", lines=5)\n",
        "    \n",
        "    run_btn.click(\n",
        "        fn=analyze_plant,\n",
        "        inputs=[image, temp, humidity, soil],\n",
        "        outputs=[diagnosis, status, alerts, recommendations]\n",
        "    )\n",
        "\n",
        "\n",
        "def build_rag_chat_tab():\n",
        "    \"\"\"Build the RAG chat tab.\"\"\"\n",
        "    gr.Markdown(\"## \ud83d\udcac RAG Chat\")\n",
        "    gr.Markdown(\"Ask questions about plant diseases using document retrieval.\")\n",
        "    \n",
        "    question = gr.Textbox(label=\"\ud83d\udd0d Query\", placeholder=\"e.g., What causes leaf spots?\", lines=2)\n",
        "    n_results = gr.Slider(1, 5, value=3, step=1, label=\"Top-K documents\")\n",
        "    run_btn = gr.Button(\"Run\", variant=\"primary\")\n",
        "    \n",
        "    retrieved_df = gr.Dataframe(headers=[\"doc_id\", \"score\", \"url\"], label=\"\ud83d\udcc4 Retrieved Documents\")\n",
        "    answer_box = gr.Textbox(label=\"\ud83e\udd16 RAG Answer\", lines=10)\n",
        "    \n",
        "    def query_rag(q, k):\n",
        "        if not q.strip():\n",
        "            return [], \"Please enter a question.\"\n",
        "        \n",
        "        q_terms, results, answer = RAGService.generate_answer(q, k=int(k))\n",
        "        rows = [[r.get(\"doc_id\"), r.get(\"score\"), r.get(\"url\")] for r in results]\n",
        "        return rows, answer\n",
        "    \n",
        "    run_btn.click(query_rag, inputs=[question, n_results], outputs=[retrieved_df, answer_box])\n",
        "\n",
        "\n",
        "def build_sync_data_tab():\n",
        "    \"\"\"Build the data sync tab.\"\"\"\n",
        "    gr.Markdown(\"## \ud83d\udd04 Sync Data\")\n",
        "    gr.Markdown(\"Upload IoT Data to Firebase\")\n",
        "    \n",
        "    sync_btn = gr.Button(\"\ud83d\udd04 Sync from Server\", variant=\"primary\")\n",
        "    sync_status = gr.Textbox(label=\"Sync Status\", lines=5)\n",
        "    \n",
        "    def sync_action():\n",
        "        msg, count = DataService.sync_from_server()\n",
        "        return msg\n",
        "    \n",
        "    sync_btn.click(sync_action, outputs=[sync_status])\n",
        "\n",
        "\n",
        "print(\"\u2705 UI Components loaded\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\ude80 13. App Builder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# TAB REGISTRY & APP BUILDER\n",
        "# =============================================================================\n",
        "\n",
        "# Tab configuration - single place to add/remove tabs\n",
        "TABS = [\n",
        "    (\"\ud83c\udf31 Realtime Dashboard\", build_realtime_dashboard_tab),\n",
        "    (\"\ud83d\udcca IoT Dashboard\", build_iot_dashboard_tab),\n",
        "    (\"\ud83d\udcc4 Generate Report\", build_generate_report_tab),\n",
        "    (\"\ud83d\uddbc\ufe0f Plant Disease Detection\", build_plant_disease_detection_tab),\n",
        "    (\"\ud83d\udcac RAG Chat\", build_rag_chat_tab),\n",
        "    (\"\ud83d\udd04 Sync Data\", build_sync_data_tab),\n",
        "]\n",
        "\n",
        "\n",
        "def build_app() -> gr.Blocks:\n",
        "    \"\"\"Build the complete Gradio application.\"\"\"\n",
        "    with gr.Blocks(title=APP_TITLE, css=CUSTOM_CSS) as demo:\n",
        "        # Header\n",
        "        gr.Markdown(f\"<h1 style='text-align:left;font-size:30px;font-weight:700;'>{APP_TITLE}</h1>\")\n",
        "        gr.Markdown(f\"<p style='text-align:left;font-size:18px;color:#666;'>{APP_SUBTITLE}</p>\")\n",
        "        \n",
        "        # Build all tabs\n",
        "        with gr.Tabs():\n",
        "            for tab_name, tab_builder in TABS:\n",
        "                with gr.Tab(tab_name):\n",
        "                    tab_builder()\n",
        "    \n",
        "    return demo\n",
        "\n",
        "\n",
        "print(\"\u2705 App Builder ready\")\n",
        "print(f\"   Configured tabs: {len(TABS)}\")\n",
        "for name, _ in TABS:\n",
        "    print(f\"   - {name}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfac 14. Launch Application"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# LAUNCH APPLICATION\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"\ud83c\udf31 Starting CloudGarden Application...\")\n",
        "    print(\"=\"*50 + \"\\n\")\n",
        "    \n",
        "    app = build_app()\n",
        "    app.launch(share=True, debug=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}